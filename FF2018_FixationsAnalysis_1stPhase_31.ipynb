{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixation analysis (initial fixations analysis, as in Kovach et al., 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fixation and trial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 26 27 28\n",
      " 29 31 32 34 35 36 39]\n",
      "Number of participants: 31\n"
     ]
    }
   ],
   "source": [
    "data_fix_1 = pd.read_csv('/Users/pradyumna/Documents/GiTs/FF2018/Output/fixation_FFA_AllConditions_31.csv') \n",
    "data_exp1 = pd.read_csv('/Users/pradyumna/Documents/GiTs/FF2018/Output/DataFoodFramingNotebook_31.csv') \n",
    "\n",
    "print (data_exp1[\"Part\"].unique())\n",
    "print ('Number of participants: ' + str(len(data_exp1[\"Part\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsaccade added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1_microSc = pd.read_csv('/Users/pradyumna/Documents/GiTs/FF2018/Output/Microfixations_AllConditions_31.csv') \n",
    "data_exp1 = data_exp1.reset_index()\n",
    "\n",
    "data_exp1['LmSacc'] = data_exp1_microSc['microfix1_drop']\n",
    "data_exp1['RmSacc'] = data_exp1_microSc['microfix2_drop']\n",
    "data_exp1['DmSacc'] = data_exp1_microSc['microfix2_drop'] - data_exp1_microSc['microfix1_drop']\n",
    "data_exp1['AbsDmSacc'] = abs(data_exp1_microSc['microfix2_drop'] - data_exp1_microSc['microfix1_drop'])\n",
    "data_exp1['TotmSacc'] = data_exp1_microSc['microfix2_drop'] + data_exp1_microSc['microfix1_drop']\n",
    "\n",
    "\n",
    "data_exp1['LmSaccTime'] = data_exp1_microSc['microfix_1_drop_timeavg']\n",
    "data_exp1['RmSaccTime'] = data_exp1_microSc['microfix_2_drop_timeavg']\n",
    "data_exp1['DmSaccTime'] = data_exp1_microSc['microfix_2_drop_timeavg'] - data_exp1_microSc['microfix_1_drop_timeavg']\n",
    "data_exp1['AbsDmSaccTime'] = abs(data_exp1_microSc['microfix_2_drop_timeavg'] - data_exp1_microSc['microfix_1_drop_timeavg'])\n",
    "\n",
    "\n",
    "\n",
    "data_exp1[\"zLmSacc\"] = z_score1(data_exp1,'Part',\"LmSacc\")\n",
    "data_exp1[\"zRmSacc\"] = z_score1(data_exp1,'Part',\"RmSacc\")\n",
    "data_exp1[\"zDmSacc\"] = z_score1(data_exp1,'Part',\"DmSacc\")\n",
    "data_exp1[\"zAbsDmSacc\"] = z_score1(data_exp1,'Part',\"AbsDmSacc\")\n",
    "data_exp1[\"zTotmSacc\"] = z_score1(data_exp1,'Part',\"TotmSacc\")\n",
    "\n",
    "data_exp1[\"zLmSaccTime\"] = z_score1(data_exp1,'Part',\"LmSaccTime\")\n",
    "data_exp1[\"zRmSaccTime\"] = z_score1(data_exp1,'Part',\"RmSaccTime\")\n",
    "data_exp1[\"zDmSaccTime\"] = z_score1(data_exp1,'Part',\"DmSaccTime\")\n",
    "data_exp1[\"zAbsDmSaccTime\"] = z_score1(data_exp1,'Part',\"AbsDmSaccTime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1=data_exp1.rename(index=str, columns={\"ChosenITM\":\"Choice\", \n",
    "                              \"ChoiceRT\":\"RT\",\n",
    "                             \"RValue\":\"RVal\",\n",
    "                             \"LValue\":\"LVal\",\n",
    "                             \"zRValue\":\"zRVal\",\n",
    "                             \"zLValue\":\"zLVal\",                    \n",
    "                             \"tDDT\":\"DDT\",\n",
    "                             \"absDDT\":\"zAbsDDT\",\n",
    "                             \"lIA_DT\":\"LDwellTime\",\n",
    "                             \"rIA_DT\":\"RDwellTime\",\n",
    "                             \"tGSF\":\"GSF\",\n",
    "                             \"lastFixat\":\"LastFixat\",\n",
    "                             \"DV\":\"DVal\",\n",
    "                             \"zDV\":\"zDVal\",\n",
    "                             \"absDV\":\"AbsDVal\",\n",
    "                             \"zAbsDV\":\"zAbsDVal\",                    \n",
    "                             \"zChoiceRT\":\"zRT\",\n",
    "                             \"FamCh\":\"ChosenFam\",\n",
    "                              \"FamUnCh\":\"UnchosenFam\",\n",
    "                              \"ValCh\":\"ChosenVal\",\n",
    "                              \"ValUnCh\":\"UnchosenVal\",\n",
    "                             \"zFamCh\":\"zChosenFam\",\n",
    "                              \"zFamUnCh\":\"zUnchosenFam\",\n",
    "                              \"zValCh\":\"zChosenVal\",\n",
    "                              \"zValUnCh\":\"zUnchosenVal\",                   \n",
    "                              \"GSFMedSplit\":\"GSFSplit\",\n",
    "                            \"DDTMedSplit\":\"DDTSplit\"})\n",
    "#data_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add column with the item with higher value for each trial\n",
    "\n",
    "data_exp1[\"zHighVal\"] = data_exp1[[\"zRVal\", \"zLVal\"]].max(axis=1)\n",
    "data_exp1[\"zLowVal\"] = data_exp1[[\"zRVal\", \"zLVal\"]].min(axis=1)\n",
    "\n",
    "data_exp1['HighValPos'] = np.where((data_exp1['zHighVal'] == data_exp1['zLVal']) , 1, 2)\n",
    "data_exp1['LowValPos'] = np.where((data_exp1['zLowVal'] == data_exp1['zLVal']) , 1, 2)\n",
    "\n",
    "## Add normalized microsaccades (nÂº of microsaccades / dwelling time)\n",
    "\n",
    "data_exp1['NormLmSacc'] = data_exp1['LmSacc']/data_exp1['LDwellTime']\n",
    "data_exp1['NormRmSacc'] = data_exp1['RmSacc']/data_exp1['RDwellTime']\n",
    "\n",
    "data_exp1['NormDmSacc']  = data_exp1['NormRmSacc'] - data_exp1['NormLmSacc'] \n",
    "data_exp1['AbsNormDmSacc']  = abs(data_exp1['NormRmSacc'] - data_exp1['NormLmSacc']) \n",
    "\n",
    "data_exp1[\"zNormDmSacc\"] = z_score1(data_exp1,'Part',\"NormDmSacc\")\n",
    "data_exp1[\"zAbsNormDmSacc\"] = z_score1(data_exp1,'Part',\"AbsNormDmSacc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20,\n",
       "       21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 34, 35, 36, 39])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exp1.Part.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 26 27 28\n",
      " 29 31 32 34 35 36 39]\n",
      "[ 1  2  3  4  5  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 26 27 28\n",
      " 29 31 32 34 35 36 39]\n"
     ]
    }
   ],
   "source": [
    "par_list = data_fix_1[\"parcode\"].unique()\n",
    "parInfoList = data_exp1[\"Part\"].unique()\n",
    "print(par_list)\n",
    "print(parInfoList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>parcode</th>\n",
       "      <th>trial</th>\n",
       "      <th>fix_item</th>\n",
       "      <th>fix_time</th>\n",
       "      <th>rt</th>\n",
       "      <th>block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>378</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>432</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>358</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>358</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>438</td>\n",
       "      <td>3327</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>348</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>740</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>748</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>292</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>339</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>284</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p1.edf</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>610</td>\n",
       "      <td>3691</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76274</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76275</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>302</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76276</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76277</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76278</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76279</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>3394</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76280</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76281</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76282</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76283</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76284</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>424</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76285</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76286</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>666</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76287</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>638</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76288</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>544</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76289</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76290</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>422</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76291</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76292</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76293</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76294</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>340</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76295</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76296</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76297</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76298</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76299</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76300</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76301</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76302</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76303</th>\n",
       "      <td>p43.edf</td>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>1905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76304 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  parcode  trial  fix_item  fix_time    rt  block\n",
       "0       p1.edf        1      0         0       437  3327    2.0\n",
       "1       p1.edf        1      0         0       164  3327    2.0\n",
       "2       p1.edf        1      0         1       302  3327    2.0\n",
       "3       p1.edf        1      0         1       198  3327    2.0\n",
       "4       p1.edf        1      0         1       378  3327    2.0\n",
       "5       p1.edf        1      0         2       432  3327    2.0\n",
       "6       p1.edf        1      0         2       262  3327    2.0\n",
       "7       p1.edf        1      0         1       358  3327    2.0\n",
       "8       p1.edf        1      0         1       358  3327    2.0\n",
       "9       p1.edf        1      0         1       438  3327    2.0\n",
       "10      p1.edf        1      1         3       215  3424    2.0\n",
       "11      p1.edf        1      1         1       338  3424    2.0\n",
       "12      p1.edf        1      1         1       348  3424    2.0\n",
       "13      p1.edf        1      1         2       740  3424    2.0\n",
       "14      p1.edf        1      1         2       748  3424    2.0\n",
       "15      p1.edf        1      1         1       352  3424    2.0\n",
       "16      p1.edf        1      1         1       280  3424    2.0\n",
       "17      p1.edf        1      1         2       292  3424    2.0\n",
       "18      p1.edf        1      1         2       111  3424    2.0\n",
       "19      p1.edf        1      2         3       339  3691    2.0\n",
       "20      p1.edf        1      2         1       116  3691    2.0\n",
       "21      p1.edf        1      2         1       240  3691    2.0\n",
       "22      p1.edf        1      2         1       198  3691    2.0\n",
       "23      p1.edf        1      2         1       328  3691    2.0\n",
       "24      p1.edf        1      2         1       226  3691    2.0\n",
       "25      p1.edf        1      2         2       424  3691    2.0\n",
       "26      p1.edf        1      2         2       182  3691    2.0\n",
       "27      p1.edf        1      2         2       284  3691    2.0\n",
       "28      p1.edf        1      2         2       168  3691    2.0\n",
       "29      p1.edf        1      2         2       610  3691    2.0\n",
       "...        ...      ...    ...       ...       ...   ...    ...\n",
       "76274  p43.edf       39    237         2       262  3394    1.0\n",
       "76275  p43.edf       39    237         2       302  3394    1.0\n",
       "76276  p43.edf       39    237         2       214  3394    1.0\n",
       "76277  p43.edf       39    237         0       112  3394    1.0\n",
       "76278  p43.edf       39    237         1       356  3394    1.0\n",
       "76279  p43.edf       39    237         1       125  3394    1.0\n",
       "76280  p43.edf       39    238         3       194  5280    1.0\n",
       "76281  p43.edf       39    238         1       106  5280    1.0\n",
       "76282  p43.edf       39    238         1       254  5280    1.0\n",
       "76283  p43.edf       39    238         1       294  5280    1.0\n",
       "76284  p43.edf       39    238         1       424  5280    1.0\n",
       "76285  p43.edf       39    238         2       356  5280    1.0\n",
       "76286  p43.edf       39    238         2       666  5280    1.0\n",
       "76287  p43.edf       39    238         2       638  5280    1.0\n",
       "76288  p43.edf       39    238         2       544  5280    1.0\n",
       "76289  p43.edf       39    238         2       174  5280    1.0\n",
       "76290  p43.edf       39    238         2       422  5280    1.0\n",
       "76291  p43.edf       39    238         1       360  5280    1.0\n",
       "76292  p43.edf       39    238         1       192  5280    1.0\n",
       "76293  p43.edf       39    238         1       316  5280    1.0\n",
       "76294  p43.edf       39    238         2       340  5280    1.0\n",
       "76295  p43.edf       39    239         3         0  5280    1.0\n",
       "76296  p43.edf       39    239         2        26  1905    1.0\n",
       "76297  p43.edf       39    239         2       166  1905    1.0\n",
       "76298  p43.edf       39    239         2       258  1905    1.0\n",
       "76299  p43.edf       39    239         2       400  1905    1.0\n",
       "76300  p43.edf       39    239         2       136  1905    1.0\n",
       "76301  p43.edf       39    239         1       284  1905    1.0\n",
       "76302  p43.edf       39    239         1       178  1905    1.0\n",
       "76303  p43.edf       39    239         1       457  1905    1.0\n",
       "\n",
       "[76304 rows x 7 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fix_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fixations info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ## Areas defined in DataViewer Reports is \n",
    "  ## 1 : Left\n",
    "  ## 2 : Right\n",
    "  ## 3 : Symbol for block\n",
    "  ## 4 : Center space\n",
    "  ## Any other area will be indicated as empty\n",
    "\n",
    "\n",
    "fixations_info = []\n",
    "\n",
    "for i in range(len(par_list)):\n",
    "    data_fix1_part = data_fix_1.loc[ data_fix_1[\"parcode\"] == par_list[i]] \n",
    "    data_info1_part = data_exp1.loc[ data_exp1[\"Part\"] == parInfoList[i]] \n",
    "    \n",
    "    trial_list = data_fix1_part[\"trial\"].unique()\n",
    "    for j in trial_list:\n",
    "        data_fix1_trial = data_fix1_part.loc[ data_fix1_part[\"trial\"] == j] \n",
    "        data_info1_trial = data_info1_part.loc[ data_info1_part[\"TrialN\"] == j+1] \n",
    "        trial_fix_list = data_fix1_trial['fix_item'].values\n",
    "        last_fix_id = trial_fix_list[len(data_fix1_trial)-1]\n",
    "        trial_fix_count = np.bincount(trial_fix_list) # the count is in order [0,1,2,3]\n",
    "        mostPopularFix =  np.argmax(trial_fix_count)\n",
    "        numMostPopularFix = trial_fix_count[mostPopularFix]  \n",
    "        ##just to visualize\n",
    "        #ii = np.nonzero(trial_fix_count)[0]\n",
    "        #print(cnp.vstack((ii,trial_fix_count[ii])).T)\n",
    "\n",
    "        if trial_fix_list[0] == 3:# if we start with central fixation, we check the next fixation as initial\n",
    "            first_fix_id = trial_fix_list[1]\n",
    "            first_fix_time = data_fix1_trial['fix_time'].values[1]\n",
    "        else:\n",
    "            first_fix_id = trial_fix_list[0]\n",
    "            first_fix_time =data_fix1_trial['fix_time'].values[0]\n",
    "    \n",
    "        last_fix_id = trial_fix_list[len(data_fix1_trial)-1]\n",
    "        last_fix_time = data_fix1_trial['fix_time'].values[len(data_fix1_trial)-1]\n",
    "        \n",
    "        total_time = data_fix1_trial['fix_time'].sum()        \n",
    "        \n",
    "        # Check identity of first/last fixation and determine the value and familiarity linked\n",
    "        \n",
    "        if first_fix_id == 1: \n",
    "            firstFixValue = float(data_info1_trial['LVal'].values)\n",
    "            firstFixFam = float(data_info1_trial['LFam'].values)\n",
    "        elif first_fix_id == 2: \n",
    "            firstFixValue = float(data_info1_trial['RVal'].values)\n",
    "            firstFixFam = float(data_info1_trial['RFam'].values)\n",
    "        else:\n",
    "            firstFixValue = np.nan\n",
    "            firstFixFam = np.nan\n",
    "\n",
    "        if last_fix_id == 1: \n",
    "            lastFixValue = float(data_info1_trial['LVal'].values)\n",
    "            lastFixFam = float(data_info1_trial['LFam'].values)\n",
    "        elif last_fix_id == 2: \n",
    "            lastFixValue = float(data_info1_trial['RVal'].values)\n",
    "            lastFixFam = float(data_info1_trial['RFam'].values)    \n",
    "        else:\n",
    "            lastFixValue = np.nan\n",
    "            lastFixFam = np.nan\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        #Characterize medium fixations\n",
    "        # Is there any medium fixations\n",
    "        fixatNum = len(data_fix1_trial)\n",
    "        \n",
    "        middleFixNum = len(data_fix1_trial) - 2\n",
    "        # Generate medium \n",
    "        \n",
    "        if middleFixNum > 2 :\n",
    "            trialFixListMedium = np.delete(trial_fix_list, -1) # delete last element of the fixation series\n",
    "            trialFixListMedium = np.delete(trialFixListMedium, 0) # delete first element of the fixation series\n",
    "            trialFixListMedium = np.bincount(trialFixListMedium)\n",
    "            mostPopularFixMed = np.argmax(trialFixListMedium)\n",
    "            numMostPopularFixMed = trialFixListMedium[mostPopularFixMed]  \n",
    "        else:\n",
    "            trialFixListMedium = [] # delete last element of the fixation series\n",
    "            trialFixListMedium = np.nan\n",
    "            mostPopularFixMed = np.nan\n",
    "            numMostPopularFixMed = np.nan\n",
    "        \n",
    "        \n",
    "        if middleFixNum > 2 :\n",
    "            middleFixTotTime =  (data_fix1_trial['fix_time'].sum() - last_fix_time - first_fix_time)       \n",
    "            middleFixTimeAvg = middleFixTotTime / middleFixNum\n",
    "        else:\n",
    "            middleFixTotTime = 0\n",
    "            middleFixTimeAvg = 0\n",
    "\n",
    "        \n",
    "        fixations_info.append([i,j,first_fix_id , first_fix_time, last_fix_id,last_fix_time, \n",
    "                               firstFixValue, firstFixFam,lastFixValue, lastFixFam,\n",
    "                               fixatNum,middleFixNum,mostPopularFix, numMostPopularFix, mostPopularFixMed, numMostPopularFixMed,\n",
    "                               middleFixTotTime,middleFixTimeAvg,total_time]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_file = pd.DataFrame(fixations_info,columns=['Part','Trial', '1stFixation', '1stFixationTime', 'LastFixation','LastFixationTime', \n",
    "                                                     'firstFixValue', 'firstFixFam','lastFixValue', 'lastFixFam',\n",
    "                               'fixatNum','middleFixNum','mostPopularFix', 'numMostPopularFix', 'mostPopularFixMed', 'numMostPopularFixMed',\n",
    "                               'middleFixTime','middleFixTimeAvg','TotalTime'])\n",
    "\n",
    "\n",
    "#fixation_file = fixation_file.drop([\"Part\", \"Trial\"], axis=1)\n",
    "#fixation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct array with the fixation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_timeline = []\n",
    "\n",
    "# select each participant\n",
    "for i in range(len(par_list)):\n",
    "    data_fix1_part = data_fix_1.loc[ data_fix_1[\"parcode\"] == par_list[i]] \n",
    "    data_info1_part = data_exp1.loc[ data_exp1[\"Part\"] == parInfoList[i]] \n",
    "    \n",
    "    trial_list = data_fix1_part[\"trial\"].unique()\n",
    "    \n",
    "    #select each trial\n",
    "    for j in trial_list:\n",
    "        data_fix1_trial = data_fix1_part.loc[ data_fix1_part[\"trial\"] == j] \n",
    "        data_info1_trial = data_info1_part.loc[ data_info1_part[\"TrialN\"] == j+1] \n",
    "        trial_rt = data_info1_trial.RT.values[0]\n",
    "        \n",
    "        fix_list = range(len(data_fix1_trial))\n",
    "        fix_id = data_fix1_trial.fix_item.values\n",
    "        fix_id_time = data_fix1_trial.fix_time.values\n",
    "        fixat_timeline = []\n",
    "        \n",
    "        #extract the timeline for each trial\n",
    "        for k in fix_list:\n",
    "                fix_time_1 = fix_id_time[k]\n",
    "                fix_id_1 = fix_id[k]\n",
    "                period_count = [fix_id_1]*int(np.round(fix_time_1/10))            \n",
    "                fixat_timeline = np.concatenate((fixat_timeline,period_count))\n",
    "            \n",
    "        fixations_timeline.append([par_list[i],j,trial_rt,fixat_timeline,])\n",
    "        \n",
    "        \n",
    "fixation_timeline = pd.DataFrame(fixations_timeline,columns=['parcode','trial', 'RT', 'fixTimeln'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcode</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "      <th>fixTimeln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3327</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3424</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3691</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8144</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6559</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5595</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2470</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6091</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4669</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4001</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3301</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2867</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3117</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10424</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2754</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5836</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3931</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3602</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5674</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2567</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2097</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3641</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4550</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2973</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2824</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3643</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2188</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3321</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6784</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2314</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7410</th>\n",
       "      <td>39</td>\n",
       "      <td>210</td>\n",
       "      <td>2713</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>39</td>\n",
       "      <td>211</td>\n",
       "      <td>2609</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412</th>\n",
       "      <td>39</td>\n",
       "      <td>212</td>\n",
       "      <td>2694</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>39</td>\n",
       "      <td>213</td>\n",
       "      <td>2761</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7414</th>\n",
       "      <td>39</td>\n",
       "      <td>214</td>\n",
       "      <td>2285</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7415</th>\n",
       "      <td>39</td>\n",
       "      <td>215</td>\n",
       "      <td>1613</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7416</th>\n",
       "      <td>39</td>\n",
       "      <td>216</td>\n",
       "      <td>2841</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7417</th>\n",
       "      <td>39</td>\n",
       "      <td>217</td>\n",
       "      <td>2258</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7418</th>\n",
       "      <td>39</td>\n",
       "      <td>218</td>\n",
       "      <td>1243</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>39</td>\n",
       "      <td>219</td>\n",
       "      <td>1767</td>\n",
       "      <td>[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>39</td>\n",
       "      <td>220</td>\n",
       "      <td>2423</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>39</td>\n",
       "      <td>221</td>\n",
       "      <td>1217</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>39</td>\n",
       "      <td>222</td>\n",
       "      <td>3420</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7423</th>\n",
       "      <td>39</td>\n",
       "      <td>223</td>\n",
       "      <td>8198</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7424</th>\n",
       "      <td>39</td>\n",
       "      <td>224</td>\n",
       "      <td>5417</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>39</td>\n",
       "      <td>225</td>\n",
       "      <td>1100</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>39</td>\n",
       "      <td>226</td>\n",
       "      <td>1789</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>39</td>\n",
       "      <td>227</td>\n",
       "      <td>4438</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>39</td>\n",
       "      <td>228</td>\n",
       "      <td>3252</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>39</td>\n",
       "      <td>229</td>\n",
       "      <td>4139</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>39</td>\n",
       "      <td>230</td>\n",
       "      <td>2098</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>39</td>\n",
       "      <td>231</td>\n",
       "      <td>2920</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>39</td>\n",
       "      <td>232</td>\n",
       "      <td>3779</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>39</td>\n",
       "      <td>233</td>\n",
       "      <td>1952</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>39</td>\n",
       "      <td>234</td>\n",
       "      <td>2133</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>39</td>\n",
       "      <td>235</td>\n",
       "      <td>1395</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>39</td>\n",
       "      <td>236</td>\n",
       "      <td>1213</td>\n",
       "      <td>[3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>39</td>\n",
       "      <td>237</td>\n",
       "      <td>3394</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "      <td>5280</td>\n",
       "      <td>[3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>39</td>\n",
       "      <td>239</td>\n",
       "      <td>1905</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7440 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      parcode  trial     RT                                          fixTimeln\n",
       "0           1      0   3327  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1           1      1   3424  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "2           1      2   3691  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "3           1      3   8144  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "4           1      4   6559  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "5           1      5   5595  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "6           1      6   2470  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7           1      7   6091  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "8           1      8   4669  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "9           1      9   4001  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "10          1     10   3301  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "11          1     11   2867  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "12          1     12   3117  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "13          1     13  10424  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "14          1     14   2754  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "15          1     15   5836  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "16          1     16   3931  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "17          1     17   3602  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "18          1     18   5674  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "19          1     19   2567  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "20          1     20   2097  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "21          1     21   3641  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "22          1     22   4550  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "23          1     23   2973  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "24          1     24   2824  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "25          1     25   3643  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "26          1     26   2188  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, ...\n",
       "27          1     27   3321  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "28          1     28   6784  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "29          1     29   2314  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "...       ...    ...    ...                                                ...\n",
       "7410       39    210   2713  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7411       39    211   2609  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7412       39    212   2694  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7413       39    213   2761  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 0.0, ...\n",
       "7414       39    214   2285  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7415       39    215   1613  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7416       39    216   2841  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7417       39    217   2258  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7418       39    218   1243  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7419       39    219   1767  [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "7420       39    220   2423  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7421       39    221   1217  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7422       39    222   3420  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7423       39    223   8198  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7424       39    224   5417  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7425       39    225   1100  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7426       39    226   1789  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, ...\n",
       "7427       39    227   4438  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7428       39    228   3252  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7429       39    229   4139  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7430       39    230   2098  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7431       39    231   2920  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7432       39    232   3779  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7433       39    233   1952  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7434       39    234   2133  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7435       39    235   1395  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7436       39    236   1213  [3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "7437       39    237   3394  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "7438       39    238   5280  [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, ...\n",
       "7439       39    239   1905  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
       "\n",
       "[7440 rows x 4 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixation_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick first XX milisec to calculate the DDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_phase_time = int(500/10)\n",
    "\n",
    "fix_1stPhase = []\n",
    "ddt_1stPhase = []\n",
    "\n",
    "# select each participant\n",
    "for i in range(len(par_list)):\n",
    "    fix_time_part = fixation_timeline.loc[ fixation_timeline[\"parcode\"] == par_list[i]] \n",
    "\n",
    "    trial_list = fixation_timeline[\"trial\"].unique()\n",
    "\n",
    "    #select each trial\n",
    "    for j in trial_list:\n",
    "        \n",
    "            fix_timeln_1stPhase = fix_time_part.loc[(fix_time_part[\"trial\"] == j)].fixTimeln.values[0]\n",
    "               \n",
    "            if first_phase_time > len(fix_timeln_1stPhase):\n",
    "                fix_1stPhase.append(np.nan)\n",
    "                ddt_1stPhase.append(np.nan)\n",
    "                continue\n",
    "            else:\n",
    "                fix_initial = fix_timeln_1stPhase[0:first_phase_time]\n",
    "                fix_1stPhase.append(fix_initial)\n",
    "\n",
    "                left_time = list(fix_initial).count(1)\n",
    "                right_time = list(fix_initial).count(2)\n",
    "\n",
    "                if left_time == 0 and right_time == 0: \n",
    "                    ddt_1stPhase.append(np.nan)\n",
    "                else:\n",
    "                    ddt_1stPhase.append((right_time - left_time) / (right_time + left_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20,\n",
       "       21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 34, 35, 36, 39])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7440"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fixation_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7440"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddt_1stPhase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'Part', 'TrialN', 'PairID', 'LItem', 'LVal',\n",
       "       'RItem', 'RVal', 'Choice', 'RT', 'Conf', 'ConfRT', 'BlockCond', 'DDT',\n",
       "       'LDwellTime', 'RDwellTime', 'GSF', 'LastFixat', 'DVal', 'zDVal',\n",
       "       'AbsDVal', 'zAbsDVal', 'zConf', 'zRT', 'DFam', 'LFam', 'RFam', 'TotFam',\n",
       "       'TotVal', 'ChosenFam', 'UnchosenFam', 'ChosenVal', 'UnchosenVal',\n",
       "       'Correct', 'LValConfBDM', 'LFamConfBDM', 'RValConfBDM', 'RFamConfBDM',\n",
       "       'zDFam', 'zTotFam', 'zTotVal', 'zChosenVal', 'zUnchosenVal',\n",
       "       'zChosenFam', 'zUnchosenFam', 'zGSF', 'zDDT', 'zAbsDDT', 'zAbsDFam',\n",
       "       'zLVal', 'zRVal', 'zLFam', 'zRFam', 'zLValConfBDM', 'zLFamConfBDM',\n",
       "       'zRValConfBDM', 'zRFamConfBDM', 'ConfSplit', 'GSFSplit', 'DDTSplit',\n",
       "       'LmSacc', 'RmSacc', 'DmSacc', 'AbsDmSacc', 'TotmSacc', 'LmSaccTime',\n",
       "       'RmSaccTime', 'DmSaccTime', 'AbsDmSaccTime', 'zLmSacc', 'zRmSacc',\n",
       "       'zDmSacc', 'zAbsDmSacc', 'zTotmSacc', 'zLmSaccTime', 'zRmSaccTime',\n",
       "       'zDmSaccTime', 'zAbsDmSaccTime', 'zHighVal', 'zLowVal', 'HighValPos',\n",
       "       'LowValPos', 'NormLmSacc', 'NormRmSacc', 'NormDmSacc', 'AbsNormDmSacc',\n",
       "       'zNormDmSacc', 'zAbsNormDmSacc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exp1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'Part', 'TrialN', 'PairID', 'LItem', 'LVal',\n",
       "       'RItem', 'RVal', 'Choice', 'RT', 'Conf', 'ConfRT', 'BlockCond', 'DDT',\n",
       "       'LDwellTime', 'RDwellTime', 'GSF', 'LastFixat', 'DVal', 'zDVal',\n",
       "       'AbsDVal', 'zAbsDVal', 'zConf', 'zRT', 'DFam', 'LFam', 'RFam', 'TotFam',\n",
       "       'TotVal', 'ChosenFam', 'UnchosenFam', 'ChosenVal', 'UnchosenVal',\n",
       "       'Correct', 'LValConfBDM', 'LFamConfBDM', 'RValConfBDM', 'RFamConfBDM',\n",
       "       'zDFam', 'zTotFam', 'zTotVal', 'zChosenVal', 'zUnchosenVal',\n",
       "       'zChosenFam', 'zUnchosenFam', 'zGSF', 'zDDT', 'zAbsDDT', 'zAbsDFam',\n",
       "       'zLVal', 'zRVal', 'zLFam', 'zRFam', 'zLValConfBDM', 'zLFamConfBDM',\n",
       "       'zRValConfBDM', 'zRFamConfBDM', 'ConfSplit', 'GSFSplit', 'DDTSplit',\n",
       "       'LmSacc', 'RmSacc', 'DmSacc', 'AbsDmSacc', 'TotmSacc', 'LmSaccTime',\n",
       "       'RmSaccTime', 'DmSaccTime', 'AbsDmSaccTime', 'zLmSacc', 'zRmSacc',\n",
       "       'zDmSacc', 'zAbsDmSacc', 'zTotmSacc', 'zLmSaccTime', 'zRmSaccTime',\n",
       "       'zDmSaccTime', 'zAbsDmSaccTime', 'zHighVal', 'zLowVal', 'HighValPos',\n",
       "       'LowValPos', 'NormLmSacc', 'NormRmSacc', 'NormDmSacc', 'AbsNormDmSacc',\n",
       "       'zNormDmSacc', 'zAbsNormDmSacc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exp1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_timeline['ddt_1st'] = ddt_1stPhase\n",
    "fixation_timeline['fixTimeln_1st'] = fix_1stPhase\n",
    "fixation_timeline['DVal'] = data_exp1['DVal'].values\n",
    "fixation_timeline['Choice'] = data_exp1['Choice'].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parcode', 'trial', 'RT', 'fixTimeln', 'ddt_1st', 'fix_1st', 'DVal',\n",
       "       'Choice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixation_timeline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation_timeline_R = fixation_timeline.copy\n",
    "fixation_timeline_R.drop(columns=['B', 'Choice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg'></a>\n",
    "# Regression Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RRuntimeError",
     "evalue": "Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  : \n  arguments imply differing number of rows: 333, 343, 369, 815, 656, 560, 247, 608, 466, 401, 329, 286, 311, 1040, 276, 584, 392, 360, 567, 256, 210, 363, 456, 297, 282, 364, 220, 332, 677, 232, 295, 837, 534, 219, 322, 321, 348, 229, 350, 446, 200, 336, 170, 744, 190, 222, 425, 352, 254, 324, 461, 634, 570, 357, 245, 212, 693, 427, 686, 671, 291, 451, 337, 215, 701, 478, 270, 465, 203, 145, 359, 738, 293, 641, 290, 474, 346, 234, 199, 154, 302, 347, 398, 262, 172, 433, 204, 248, 339, 233, 362, 739, 253, 175, 259, 576, 195, 162, 272, 258, 353, 707, 409, 260, 323, 625, 459, 235, 475, 345, 173, 202, 52, 549, 148, 147, 242, 561, 320, 316, 194, 206, 156, 123, 372, 177, 157, 542, 520, 411, 317, 168, 166, 187, 264, 361, 185, 201, 198, 171, 236, 421, 255, 250, 251, 161, 298, 217, 184, 158, 237, 249, 274, 394, 419, 377, 485, 526, 564, 186, 416, 283, 226, 150, 174, 209, 188, 482, 211, 457, 444, 176, 153, 155, 129, 420, 182, 146, 495, 642, 512, 428, 472, 539, 429, 391, 442, 303, 491, 540\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-917ad82e8037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i fixation_timeline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/pradyumna/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-130>\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    688\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name '%s' is not defined\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mlocalconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m                     \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mtmpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_graphics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mpattern_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\link\\{(.+?)\\}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mnew_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mnew_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    825\u001b[0m                             '1 positional argument')\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py\u001b[0m in \u001b[0;36mpy2ri_pandasdataframe\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStrVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mpy2ri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPandasIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/vectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, stringsasfactor)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# Call R's data frame constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseenv_ri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.frame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobalenv_ri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  : \n  arguments imply differing number of rows: 333, 343, 369, 815, 656, 560, 247, 608, 466, 401, 329, 286, 311, 1040, 276, 584, 392, 360, 567, 256, 210, 363, 456, 297, 282, 364, 220, 332, 677, 232, 295, 837, 534, 219, 322, 321, 348, 229, 350, 446, 200, 336, 170, 744, 190, 222, 425, 352, 254, 324, 461, 634, 570, 357, 245, 212, 693, 427, 686, 671, 291, 451, 337, 215, 701, 478, 270, 465, 203, 145, 359, 738, 293, 641, 290, 474, 346, 234, 199, 154, 302, 347, 398, 262, 172, 433, 204, 248, 339, 233, 362, 739, 253, 175, 259, 576, 195, 162, 272, 258, 353, 707, 409, 260, 323, 625, 459, 235, 475, 345, 173, 202, 52, 549, 148, 147, 242, 561, 320, 316, 194, 206, 156, 123, 372, 177, 157, 542, 520, 411, 317, 168, 166, 187, 264, 361, 185, 201, 198, 171, 236, 421, 255, 250, 251, 161, 298, 217, 184, 158, 237, 249, 274, 394, 419, 377, 485, 526, 564, 186, 416, 283, 226, 150, 174, 209, 188, 482, 211, 457, 444, 176, 153, 155, 129, 420, 182, 146, 495, 642, 512, 428, 472, 539, 429, 391, 442, 303, 491, 540\n"
     ]
    }
   ],
   "source": [
    "%R -i fixation_timeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(car)\n",
    "library(optimx)\n",
    "library(ggplot2)\n",
    "library(MASS)\n",
    "library(broom)\n",
    "library(dplyr)\n",
    "library(reshape2)\n",
    "library(arm)\n",
    "library(multcomp)\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Separating the data for both conditions \n",
    "#data_exp1_Like <- data_exp11[ which(data_exp11$BlockCond=='1'), ]\n",
    "#data_exp1_DisLike <- data_exp11[ which(data_exp11$BlockCond=='2'), ]\n",
    "data_exp1_Like <- data_expL\n",
    "data_exp1_DisLike <- data_expD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regCond'></a>\n",
    "# 3.1.  Regressions per Condition (Like/Dislike)\n",
    "## ChoiceITM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Figure replicating Folke 2016.\n",
    "\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation), data=data_exp1_Like, family=binomial(link=\"logit\"))\n",
    "ModelChoiceD_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation), data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-5, 5) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp11 = pd.DataFrame()\n",
    "data_exp1 = data_exp1.reset_index()\n",
    "fixation_file =fixation_file.reset_index()\n",
    "frames_list = [data_exp1,fixation_file]\n",
    "data_exp11 = pd.concat(frames_list, axis = 1)\n",
    "#fixation_file.to_csv(\"Output/DataAllFixINcluTEST31.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp11 = data_exp11.drop(['level_0','index','Unnamed: 0',], axis=1)\n",
    "list(data_exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the variables to calculate the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl_plot(data_exp11,'zAbsDVal', \"|DVal|\",'LastFixationTime','LastFixationTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColsSelected = data_exp11.loc[:, ['Choice','DFam','DVal','zAbsDVal','zAbsDFam','zConf','zRT', 'zGSF', \n",
    "                                     'zDDT','zAbsDDT', 'TotVal','TotFam', 'LVal','RVal','LFam','RFam', \n",
    "                                     'ChosenFam','UnchosenFam','ChosenVal', 'UnchosenVal','1stFixation','1stFixationTime', 'LastFixation','LastFixationTime','firstFixValue','firstFixFam','lastFixValue',\n",
    " 'lastFixFam', 'fixatNum', 'middleFixNum',  'mostPopularFix', 'numMostPopularFix','mostPopularFixMed','numMostPopularFixMed', 'middleFixTime', 'middleFixTimeAvg']]\n",
    "dataColsSelected\n",
    "data_corr = dataColsSelected.corr(method='pearson')\n",
    "data_corr\n",
    "# plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(50,50))         # Sample figsize in inches\n",
    "sns.heatmap(data_corr, \n",
    "       xticklabels=data_corr.columns,\n",
    "       yticklabels=data_corr.columns, annot=True, annot_kws={\"size\": 15})\n",
    "\n",
    "ax.set_title('Correlations Like + Dislike',fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Like Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Condition \n",
    "data_expL = data_exp11.loc[data_exp11['BlockCond'] == 1] # 1 = Like, 2 = Dislike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColsSelected = data_expL.loc[:, ['Choice','DFam','DVal','zAbsDVal','zAbsDFam','zConf','zRT', 'zGSF', \n",
    "                                     'zDDT','zAbsDDT', 'TotVal','TotFam', 'LVal','RVal','LFam','RFam', \n",
    "                                     'ChosenFam','UnchosenFam','ChosenVal', 'UnchosenVal','1stFixation','1stFixationTime', 'LastFixation','LastFixationTime','firstFixValue','firstFixFam','lastFixValue',\n",
    " 'lastFixFam', 'fixatNum', 'middleFixNum',  'mostPopularFix', 'numMostPopularFix','mostPopularFixMed','numMostPopularFixMed', 'middleFixTime', 'middleFixTimeAvg']]\n",
    "dataColsSelected\n",
    "data_corr = dataColsSelected.corr(method='pearson')\n",
    "data_corr\n",
    "# plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(50,50))         # Sample figsize in inches\n",
    "sns.heatmap(data_corr, \n",
    "       xticklabels=data_corr.columns,\n",
    "       yticklabels=data_corr.columns, annot=True, annot_kws={\"size\": 15})\n",
    "\n",
    "ax.set_title('Correlations Like Condition',fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dislike Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Condition \n",
    "data_expD = data_exp11.loc[data_exp11['BlockCond'] == 2] # 1 = Like, 2 = Dislike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColsSelected = data_expD.loc[:, ['Choice','DFam','DVal','zAbsDVal','zAbsDFam','zConf','zRT', 'zGSF', \n",
    "                                     'zDDT','zAbsDDT', 'TotVal','TotFam', 'LVal','RVal','LFam','RFam', \n",
    "                                     'ChosenFam','UnchosenFam','ChosenVal', 'UnchosenVal','1stFixation','1stFixationTime', 'LastFixation','LastFixationTime','firstFixValue','firstFixFam','lastFixValue',\n",
    " 'lastFixFam', 'fixatNum', 'middleFixNum',  'mostPopularFix', 'numMostPopularFix','mostPopularFixMed','numMostPopularFixMed', 'middleFixTime', 'middleFixTimeAvg']]\n",
    "dataColsSelected\n",
    "data_corr = dataColsSelected.corr(method='pearson')\n",
    "data_corr\n",
    "# plot the heatmap\n",
    "fig, ax = plt.subplots(figsize=(50,50))         # Sample figsize in inches\n",
    "sns.heatmap(data_corr, \n",
    "       xticklabels=data_corr.columns,\n",
    "       yticklabels=data_corr.columns, annot=True, annot_kws={\"size\": 15})\n",
    "\n",
    "ax.set_title('Correlations Dislike Condition',fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biases for like and dislike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the last fixation bias for like and dislike per participant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_bias_part_dislike =[]\n",
    "choice_bias_part_like =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    choice_bias_part_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].LastFixation.values))\n",
    "    choice_bias_part_like.append(mean(data_expL.loc[data_expL['Part'] == i].LastFixation.values))\n",
    "    \n",
    "ttestsPlot2(choice_bias_part_like, choice_bias_part_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'Gaze (Left Item =1 , Right Item = 2)', title = 'Last-Fixations Biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_bias_corr_part_dislike =[]\n",
    "choice_bias_incorr_part_dislike =[]\n",
    "choice_bias_corr_part_like = []\n",
    "choice_bias_incorr_part_like = []\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    choice_bias_corr_part_dislike.append(mean(data_expD.loc[(data_expD['Part'] == i) & (data_expD['Correct'] == 1)].LastFixation.values))\n",
    "    choice_bias_incorr_part_dislike.append(mean(data_expD.loc[(data_expD['Part'] == i) & (data_expD['Correct'] == 0)].LastFixation.values))\n",
    "\n",
    "    choice_bias_corr_part_like.append(mean(data_expL.loc[(data_expL['Part'] == i) & (data_expL['Correct'] == 1)].LastFixation.values))\n",
    "    choice_bias_incorr_part_like.append(mean(data_expL.loc[(data_expL['Part'] == i) & (data_expL['Correct'] == 0)].LastFixation.values))\n",
    "\n",
    "ttestsPlot2(choice_bias_corr_part_dislike, choice_bias_incorr_part_dislike,'#4F6A9A','#AC5255',\"Correct\",  \"Incorrect\",ylab = 'Gaze (Left Item =1 , Right Item = 2)', title = 'Last-Fixations Biases Dislike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttestsPlot2(choice_bias_corr_part_like, choice_bias_incorr_part_like,'#4F6A9A','#AC5255',\"Correct\",  \"Incorrect\",ylab = 'Gaze (Left Item =1 , Right Item = 2)', title = 'Last-Fixations Biases Like')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  * No bias differences were found significant for like or dislike frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the first fixation bias for like and dislike per participant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_bias_part_dislike =[]\n",
    "choice_bias_part_like =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    choice_bias_part_dislike.append(mean(data_expD.loc[data_expD['Part'] == i]['1stFixation'].values))\n",
    "    choice_bias_part_like.append(mean(data_expL.loc[data_expL['Part'] == i]['1stFixation'].values))\n",
    "    \n",
    "ttestsPlot2(choice_bias_part_like, choice_bias_part_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'Gaze (Left Item =1 , Right Item = 2)', title = 'First-Fixations Biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does last fixation goes to chosen item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recall that the fixation areas were defined\n",
    "  ## 1 : Left\n",
    "  ## 2 : Right\n",
    "  ## 3 : Symbol for block\n",
    "  ## 4 : Center space\n",
    "  ## Any other area will be indicated as empty\n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['LastFixChosen'] = np.where(((data_expD['LastFixation'] == 1 ) & (data_expD['Choice'] == 0)) | ((data_expD['LastFixation'] == 2 ) & (data_expD['Choice'] == 1)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['LastFixChosen'] = np.where(((data_expL['LastFixation'] == 1 ) & (data_expL['Choice'] == 0)) | ((data_expL['LastFixation'] == 2 ) & (data_expL['Choice'] == 1)), 1 , 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for like\n",
    "Dval_lastFix = []\n",
    "for i in range(len(data_expD)):\n",
    "        if (data_expD.LastFixation.values[i]== 2 ): # if last fixations goes to the right option keep DVal\n",
    "            Dval_lastFix.append(data_expD.RVal.values[i]-data_expD.LVal.values[i])\n",
    "        else:\n",
    "            Dval_lastFix.append(data_expD.LVal.values[i]-data_expD.RVal.values[i])\n",
    "\n",
    "data_expD[\"DVal_LastFix\"] = Dval_lastFix\n",
    "\n",
    "# for dislike\n",
    "Dval_lastFix = []\n",
    "for i in range(len(data_expL)):\n",
    "        if (data_expL.LastFixation.values[i]== 2 ): # if last fixations goes to the right option keep DVal\n",
    "            Dval_lastFix.append(data_expL.RVal.values[i]-data_expL.LVal.values[i])\n",
    "        else:\n",
    "            Dval_lastFix.append(data_expL.LVal.values[i]-data_expL.RVal.values[i])\n",
    "\n",
    "data_expL[\"DVal_LastFix\"] = Dval_lastFix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-scored\n",
    "data_expD['zDVal_LastFix'] = z_score1(data_expD,'Part',\"DVal_LastFix\")\n",
    "data_expL['zDVal_LastFix'] = z_score1(data_expL,'Part',\"DVal_LastFix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].LastFixChosen.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].LastFixChosen.values))\n",
    "    \n",
    "ttestsBarPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(LastFix = Chosen)', title = 'Last-Fix and Choice coincidence')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between Last fixation and choice \n",
    "## 0 : no coincidence at all between last fixation and choice \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_like_dislike (data_expL,data_expD,'Like','Dislike', xaxis='DVal_LastFix', yaxis='LastFixChosen', ylab='P(LastFix = Chosen)', xlab='ÎVal (Last Seen - Other item)',modlowcol='#4F6A9A',modhighcol='#AC5255', parvar='Part')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_like_dislike_bins (data_expL,data_expD,'Like','Dislike', xaxis='zDVal_LastFix', yaxis='LastFixChosen', ylab='P(LastFix = Chosen)', xlab='ÎVal (Last Seen - Other item)',modlowcol='#4F6A9A',modhighcol='#AC5255', parvar='Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_like_dislike_plotAndbins(data_expL,data_expD,'Like','Dislike', xaxis='zDVal_LastFix', yaxis='LastFixChosen', ylab='P(LastFix = Chosen)', xlab='ÎVal (Last Seen - Other item)',modlowcol='#4F6A9A',modhighcol='#AC5255', parvar='Part')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_like_dislike_onlyOne(data_expL,'Like', xaxis='zDVal_LastFix', yaxis='LastFixChosen', ylab='P(LastFix = Chosen)', xlab='ÎVal (Last Seen - Other item)',modlowcol='#4F6A9A', parvar='Part')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does last fixation goes to higher value item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recall that the fixation areas were defined\n",
    "  ## 1 : Left\n",
    "  ## 2 : Right\n",
    "  ## 3 : Symbol for block\n",
    "  ## 4 : Center space\n",
    "  ## Any other area will be indicated as empty\n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['LastFixHighV'] = np.where(((data_expD['LastFixation'] == 1 ) & (data_expD['HighValPos'] == 1)) | ((data_expD['HighValPos'] == 2 ) & (data_expD['HighValPos'] == 2)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['LastFixHighV'] = np.where(((data_expL['LastFixation'] == 1 ) & (data_expL['HighValPos'] == 1)) | ((data_expL['HighValPos'] == 2 ) & (data_expL['HighValPos'] == 2)), 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].LastFixHighV.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].LastFixHighV.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(LastFix = HighVal)', title = 'Last-Fix and High-Value-Item coincidence')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between Last fixation and choice \n",
    "## 0 : no coincidence at all between last fixation and choice \n",
    "\n",
    "\n",
    " # One sample t-TEST against 0.5 (chance observation)\n",
    "    \n",
    "[sD, pD] = stats.ttest_1samp(lastfix_chosen_dislike, 0.6, axis=0)\n",
    "[sL, pL] = stats.ttest_1samp(lastfix_chosen_like, 0.6, axis=0)\n",
    "\n",
    "print (\"[Dislike 0.5] : t =  \" + str(round(sD,3)) + \" ; p =\" + str(round(pD,5)) )\n",
    "print (\"[Like 0.5] : t =  \" + str(round(sL,3)) + \" ; p =\" + str(round(pL,5)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  * In both frames, participants tend to last fixate the item with higher value, however, in dislike that behaviour significantly lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does time spent observing one item (DDT) goes to the chosen item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that the fixation areas were defined\n",
    "  ## 1 : Left\n",
    "  ## 2 : Right\n",
    "  ## 3 : Symbol for block\n",
    "  ## 4 : Center space\n",
    "  ## Any other area will be indicated as empty\n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['DDTChoice'] = np.where(((data_expD['DDT'] < 0 ) & (data_expD['Choice'] == 0)) | ((data_expD['DDT'] > 0 ) & (data_expD['Choice'] == 1)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['DDTChoice'] = np.where(((data_expL['DDT'] < 0 ) & (data_expL['Choice'] == 0)) | ((data_expL['DDT'] > 0 ) & (data_expL['Choice'] == 1)), 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].DDTChoice.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].DDTChoice.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(DDT = Choice)', title = 'DDT and Choice coincidence')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between Last fixation and choice \n",
    "## 0 : no coincidence at all between last fixation and choice \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does time spent observing one item (DDT) goes to higher value item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recall that the fixation areas were defined\n",
    "  ## 1 : Left\n",
    "  ## 2 : Right\n",
    "  ## 3 : Symbol for block\n",
    "  ## 4 : Center space\n",
    "  ## Any other area will be indicated as empty\n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['DDTHighV'] = np.where(((data_expD['DDT'] < 0 ) & (data_expD['HighValPos'] == 1)) | ((data_expD['DDT'] > 0 ) & (data_expD['HighValPos'] == 2)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['DDTHighV'] = np.where(((data_expL['DDT'] < 0 ) & (data_expL['HighValPos'] == 1)) | ((data_expL['DDT'] > 0 ) & (data_expL['HighValPos'] == 2)), 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].DDTHighV.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].DDTHighV.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(DDT goes to HighVal', title = 'DDT and HighVal coincidence')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between Last fixation and choice \n",
    "## 0 : no coincidence at all between last fixation and choice \n",
    "\n",
    "# Is it significant the magnitude of DDT in contrast to chance observation (DDT = 0.5)\n",
    "\n",
    " # One sample t-TEST against 0.5 (chance observation)\n",
    "    \n",
    "[sD, pD] = stats.ttest_1samp(lastfix_chosen_dislike, 0.6, axis=0)\n",
    "[sL, pL] = stats.ttest_1samp(lastfix_chosen_like, 0.6, axis=0)\n",
    "\n",
    "print (\"[Dislike] : t =  \" + str(round(sD,3)) + \" ; p =\" + str(round(pD,5)) )\n",
    "print (\"[Like] : t =  \" + str(round(sL,3)) + \" ; p =\" + str(round(pL,5)) )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  * IN both frames the participants look mostly the item they'll choose, independently if it is the one with higher ot lower value  (.\n",
    "####  * We observe that if we observe the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do microsaccades go to the chosen item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if the higher number of microsaccades is observed for the chosen item. \n",
    "## ---  FOR DISLIKE\n",
    "data_expD['MicroSaccChoice'] = np.where(((data_expD['zLmSacc'] > data_expD['zRmSacc']) & (data_expD['Choice'] == 0)) | ((data_expD['zLmSacc'] < data_expD['zRmSacc'] ) & (data_expD['Choice'] == 1)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['MicroSaccChoice'] = np.where(((data_expL['zLmSacc'] > data_expL['zRmSacc'] ) & (data_expL['Choice'] == 0)) | ((data_expL['zLmSacc'] < data_expL['zRmSacc'] ) & (data_expL['Choice'] == 1)), 1 , 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].MicroSaccChoice.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].MicroSaccChoice.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(MicroSaccades = Choice)', title = 'Microsaccades and Choice coincidence')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between number of microsaccades and choice \n",
    "## 0 : no coincidence at all between last microsaccades and choice \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do microsaccades go to higher value item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if the higher number of microsaccades is linked for the high value item. \n",
    "\n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['MicroSaccHighV'] = np.where(((data_expD['zLmSacc'] > data_expD['zRmSacc']) & (data_expD['HighValPos'] == 1)) | ((data_expD['zLmSacc'] < data_expD['zRmSacc'] ) & (data_expD['HighValPos'] == 2)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['MicroSaccHighV'] = np.where(((data_expL['zLmSacc'] > data_expL['zRmSacc']) & (data_expL['HighValPos'] == 1)) | ((data_expL['zLmSacc'] < data_expL['zRmSacc'] ) & (data_expL['HighValPos'] == 2)), 1 , 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].MicroSaccHighV.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].MicroSaccHighV.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(Microsaccades go to HighVal', title = '')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between microsaccades and choice \n",
    "## 0 : no coincidence at all between microsaccades and choice \n",
    "\n",
    "# Is it significant the magnitude of DDT in contrast to chance observation (DDT = 0.5)\n",
    "\n",
    " # One sample t-TEST against 0.5 (chance observation)\n",
    "    \n",
    "[sD, pD] = stats.ttest_1samp(lastfix_chosen_dislike, 0.6, axis=0)\n",
    "[sL, pL] = stats.ttest_1samp(lastfix_chosen_like, 0.6, axis=0)\n",
    "\n",
    "print (\"[Dislike] : t =  \" + str(round(sD,3)) + \" ; p =\" + str(round(pD,5)) )\n",
    "print (\"[Like] : t =  \" + str(round(sL,3)) + \" ; p =\" + str(round(pL,5)) )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do normalized microsaccades go to the chosen item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if the higher number of microsaccades is observed for the chosen item. \n",
    "## ---  FOR DISLIKE\n",
    "data_expD['NormMSaccChoice'] = np.where(((data_expD['NormLmSacc'] > data_expD['NormRmSacc']) & (data_expD['Choice'] == 0)) | ((data_expD['NormLmSacc'] < data_expD['NormRmSacc'] ) & (data_expD['Choice'] == 1)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['NormMSaccChoice'] = np.where(((data_expL['NormLmSacc'] > data_expL['NormRmSacc'] ) & (data_expL['Choice'] == 0)) | ((data_expL['NormLmSacc'] < data_expL['NormRmSacc'] ) & (data_expL['Choice'] == 1)), 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].NormMSaccChoice.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].NormMSaccChoice.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(NormMicrSacc = Choice)', title = '')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between number of microsaccades and choice \n",
    "## 0 : no coincidence at all between last microsaccades and choice \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do normalized microsaccades go to higher value item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if the higher number of microsaccades is linked for the high value item. \n",
    "\n",
    "## ---  FOR DISLIKE\n",
    "data_expD['NormMSaccHighV'] = np.where(((data_expD['NormLmSacc'] > data_expD['NormRmSacc']) & (data_expD['HighValPos'] == 1)) | ((data_expD['NormLmSacc'] < data_expD['NormRmSacc'] ) & (data_expD['HighValPos'] == 2)), 1 , 0)\n",
    "\n",
    "## ---  FOR LIKE\n",
    "data_expL['NormMSaccHighV'] = np.where(((data_expL['NormLmSacc'] > data_expL['NormRmSacc'] ) & (data_expL['HighValPos'] == 1)) | ((data_expL['NormLmSacc'] < data_expL['NormRmSacc'] ) & (data_expL['HighValPos'] == 2)), 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expD[['Choice','LastFixation','LastFix&Chosen']]\n",
    "\n",
    "lastfix_chosen_like =[]\n",
    "lastfix_chosen_dislike =[]\n",
    "\n",
    "for i in data_expD.Part.unique():\n",
    "    lastfix_chosen_dislike.append(mean(data_expD.loc[data_expD['Part'] == i].NormMSaccHighV.values))\n",
    "    lastfix_chosen_like.append(mean(data_expL.loc[data_expL['Part'] == i].NormMSaccHighV.values))\n",
    "    \n",
    "ttestsPlot2(lastfix_chosen_like, lastfix_chosen_dislike,'#4F6A9A','#AC5255',\"Like\",  \"Dislike\",ylab = 'P(NormMicrSacc go to HighVal', title = '')\n",
    "\n",
    "## for this case:\n",
    "## 1 : total coincidence between microsaccades and choice \n",
    "## 0 : no coincidence at all between microsaccades and choice \n",
    "\n",
    "# Is it significant the magnitude of DDT in contrast to chance observation (DDT = 0.5)\n",
    "\n",
    " # One sample t-TEST against 0.5 (chance observation)\n",
    "    \n",
    "[sD, pD] = stats.ttest_1samp(lastfix_chosen_dislike, 0.6, axis=0)\n",
    "[sL, pL] = stats.ttest_1samp(lastfix_chosen_like, 0.6, axis=0)\n",
    "\n",
    "print (\"[Dislike] : t =  \" + str(round(sD,3)) + \" ; p =\" + str(round(pD,5)) )\n",
    "print (\"[Like] : t =  \" + str(round(sL,3)) + \" ; p =\" + str(round(pL,5)) )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg'></a>\n",
    "# Regression Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R -i data_expD -i data_expL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(car)\n",
    "library(optimx)\n",
    "library(ggplot2)\n",
    "library(MASS)\n",
    "library(broom)\n",
    "library(dplyr)\n",
    "library(reshape2)\n",
    "library(arm)\n",
    "library(multcomp)\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%R\n",
    "##Change Column name for better regression presentation\n",
    "#colnames(data_exp1)[which(names(data_exp1) == \"zChoiceRT\")] <- \"zRT\"\n",
    "#colnames(data_exp1)[which(names(data_exp1) == \"ChoiceRT\")] <- \"RT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Separating the data for both conditions \n",
    "#data_exp1_Like <- data_exp11[ which(data_exp11$BlockCond=='1'), ]\n",
    "#data_exp1_DisLike <- data_exp11[ which(data_exp11$BlockCond=='2'), ]\n",
    "data_exp1_Like <- data_expL\n",
    "data_exp1_DisLike <- data_expD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regCond'></a>\n",
    "# 3.1.  Regressions per Condition (Like/Dislike)\n",
    "## ChoiceITM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Figure replicating Folke 2016.\n",
    "\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation), data=data_exp1_Like, family=binomial(link=\"logit\"))\n",
    "ModelChoiceD_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation), data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-5, 5) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Figure replicating Folke 2016.\n",
    "\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation) +  zDmSacc, data=data_exp1_Like, family=binomial(link=\"logit\"))\n",
    "ModelChoiceD_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal + zDDT + zConf:zDDT + factor(LastFixation) + zDmSacc, data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-5, 5) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Figure replicating Folke 2016.\n",
    "\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal +  zConf:zDDT  +  zDmSacc, data=data_exp1_Like, family=binomial(link=\"logit\"))\n",
    "ModelChoiceD_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal +  zConf:zDDT  + zDmSacc, data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Figure replicating Folke 2016.\n",
    "\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal  + zNormDmSacc, data=data_exp1_Like,  family=binomial(link=\"logit\") )\n",
    "ModelChoiceD_1 <- glm(Choice ~ zDVal + zConf + zTotVal + zDVal:zConf + zDVal:zTotVal  + zNormDmSacc, data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-1.1, 1.5) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#title\n",
    "title_plot = (\"zConfidence\")\n",
    "\n",
    "ModelConfidenceL_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zGSF , data=data_exp1_Like)\n",
    "ModelConfidenceD_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zGSF, data=data_exp1_DisLike)\n",
    "\n",
    "BIC1 = BIC(ModelConfidenceL_2)\n",
    "BIC2 = BIC(ModelConfidenceD_2)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelConfidenceD_2,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-.5, .5) ,main=title_plot)\n",
    "coefplot(ModelConfidenceL_2, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#title\n",
    "title_plot = (\"zConfidence\")\n",
    "\n",
    "ModelConfidenceL_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zGSF + factor(LastFixHighV)  , data=data_exp1_Like)\n",
    "ModelConfidenceD_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zGSF + factor(LastFixHighV)  , data=data_exp1_DisLike)\n",
    "\n",
    "BIC1 = BIC(ModelConfidenceL_2)\n",
    "BIC2 = BIC(ModelConfidenceD_2)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelConfidenceD_2,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-.5, .5) ,main=title_plot)\n",
    "coefplot(ModelConfidenceL_2, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#title\n",
    "title_plot = (\"zConfidence\")\n",
    "\n",
    "ModelConfidenceL_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zAbsNormDmSacc  , data=data_exp1_Like)\n",
    "ModelConfidenceD_2 <- glm(zConf ~  zAbsDVal +  zRT + zTotVal + zAbsNormDmSacc, data=data_exp1_DisLike)\n",
    "\n",
    "BIC1 = BIC(ModelConfidenceL_2)\n",
    "BIC2 = BIC(ModelConfidenceD_2)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelConfidenceD_2,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-.5, .5) ,main=title_plot)\n",
    "coefplot(ModelConfidenceL_2, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImpPkg'></a>\n",
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy', 'pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame as DF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "#np.random.seed(sum(map(ord, \"distributions\")))\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # packages for the logistic regression function to plot the logistic regression \n",
    "import scipy\n",
    "from scipy import stats, integrate\n",
    "from scipy.stats import mode\n",
    "from scipy.stats.stats import pearsonr # Pearson's correlation\n",
    "from copy import copy as copy\n",
    "import operator as operator\n",
    "import pylab\n",
    "\n",
    "# Plotting tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%pylab inline\n",
    "figsize(5, 5)\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "# Added to avoid OMP:error#15\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "# Set up interface with R\n",
    "# Make it easy to set and find values in a multi-index DF\n",
    "idx = pd.IndexSlice\n",
    "# Set up interface with R\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RRuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "# Use in case the libraries are not available in the system\n",
    "#install.packages('lme4')\n",
    "#install.packages(\"car\")\n",
    "#install.packages(\"ggplot2\")\n",
    "#install.packages(\"broom\")\n",
    "#install.packages(\"arm\")\n",
    "#install.packages(\"ggplot2\")\n",
    "#install.packages(\"optimx\")\n",
    "#install.packages(\"multcomp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LoadFunc'></a>\n",
    "# 2. Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taken from Folke et al. (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_densities(data, var, xlim=(0,100), rug=True):\n",
    "    # a counter that tells us where a given participant's data should be plotted\n",
    "    order = 1\n",
    "\n",
    "    # a list of all the participants in the dataset\n",
    "    participants = data.loc[:, 'Part'].unique()\n",
    "\n",
    "    # defining the figure size\n",
    "    sns.set_style('white')\n",
    "    fig = figure(figsize=(15,70))\n",
    "\n",
    "    for x in participants:\n",
    "        # defining the sub figures\n",
    "            sub={}\n",
    "            sub['%s' % x] = plt.subplot(len(participants)/2, 3, order)\n",
    "            sns.kdeplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x], shade=True)\n",
    "            #if rug==True:\n",
    "            #    sns.rugplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x])\n",
    "            sub['%s' % x].set_title('participant %s' % x)\n",
    "            #sub['%s' % x].set_xlim(xlim)\n",
    "            order += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split variable into participantwise quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsplit(DF, input, quantiles):\n",
    "    qvalues = pd.qcut(DF[input], quantiles, labels = range(1, quantiles+1),duplicates= 'drop')\n",
    "\n",
    "    return qvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full simple logistic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_all (moderator, modhigh, modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modhighcol='#000000', modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==0)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==0)].index, yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    print ('Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "\n",
    "    # fitting the predictive logistic model for the high_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==1)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==1)].index, yaxis])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    \n",
    "    print ('high measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "\n",
    "\n",
    "    #Plotting the binned data\n",
    "    data['DVBin2'] = data.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values\n",
    "    \n",
    "    # determine the x coordinates\n",
    "    x_cords= data.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "    # determine low y coordinates\n",
    "    y_cords_low = data.loc[(data[moderator]==0), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine low y standard errors\n",
    "    test = pd.DataFrame(data.loc[(data[moderator]==0), :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    \n",
    "    # determine high y coordinates\n",
    "    y_cords_high = data.loc[(data[moderator]==1), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine high y standard errors\n",
    "    test2 = pd.DataFrame(data.loc[data[moderator]==1, :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    # plot the low points\n",
    "    plt.scatter(x_cords, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "    # plot low error bars\n",
    "    plt.errorbar(x_cords, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "    \n",
    "    # plot the high points\n",
    "    plt.scatter(x_cords, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "    # plot high error bars\n",
    "    plt.errorbar(x_cords, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "    \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full simple logistic graph (no bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_simpl (moderator, modhigh, modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modhighcol='#000000', modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==0)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==0)].index, yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('Low measure coef',clf.coef_)\n",
    "    \n",
    "    # fitting the predictive logistic model for the high_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==1)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==1)].index, yaxis])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('High measure coef',clf.coef_)\n",
    "\n",
    "\n",
    "\n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5) \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Coefficients Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot(regtable, intercept=False, title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "\n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    if intercept == True:\n",
    "        XLim = (0.75, len(regtable.columns) + 0.25)\n",
    "        YLim = (round_to_5(regtable.loc['CImin', :].min()-0.1), round_to_5(regtable.loc['CImax', :].max()+0.2))\n",
    "    else:\n",
    "        XLim = (0.75, len(regtable.columns) - 0.75)\n",
    "        YLim = (round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()-0.2), round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()+0.2))\n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = ['#000000'] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.plot(position, regtable.loc['coefficient', Coefficient], marker='o', ms=8, color=colourlist[position-1],)\n",
    "        ax.errorbar(position, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color=colourlist[position-1])\n",
    "\n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Fixed Effects Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot2(regtable,regtable2, intercept=False, title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "\n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "\n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    \n",
    "       \n",
    "    \n",
    "    if intercept == True:\n",
    "        \n",
    "        XLim = (0.75, len(regtable.columns) + 0.25)\n",
    "        \n",
    "        #Determine the Ymax and Ymin for both regresions results\n",
    "        if round_to_5(regtable.loc['CImin', :].min()) < round_to_5(regtable2.loc['CImin', :].min()):\n",
    "            Ymin = round_to_5(regtable.loc['CImin', :].min()-0.5)\n",
    "        else :\n",
    "            Ymin = round_to_5(regtable2.loc['CImin',:].min()-0.5)\n",
    "        if round_to_5(regtable.loc['CImax', :].max()) > round_to_5(regtable2.loc['CImax', :].max()):\n",
    "            Ymax = round_to_5(regtable.loc['CImax', :].max()+0.5)\n",
    "        else :\n",
    "            Ymax = round_to_5(regtable2.loc['CImax', :].max()+0.5)      \n",
    "\n",
    "        YLim = (Ymin, Ymax)    \n",
    "    else:\n",
    "        XLim = (0.75, len(regtable.columns) - 0.75)\n",
    "        \n",
    "        #Determine the Ymax and Ymin for both regresions results\n",
    "        if round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()) < round_to_5(regtable2.loc['CImin', regtable.columns[1]:].min()):\n",
    "            Ymin = round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()-0.5)\n",
    "        else :\n",
    "            Ymin = round_to_5(regtable2.loc['CImin',regtable.columns[1]:].min()-0.5)\n",
    "        if round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()) > round_to_5(regtable2.loc['CImax', regtable.columns[1]:].max()):\n",
    "            Ymax = round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()+0.5)\n",
    "        else :\n",
    "            Ymax = round_to_5(regtable2.loc['CImax', regtable.columns[1]:].max()+0.5)      \n",
    "        \n",
    "        YLim = (Ymin, Ymax)\n",
    "    \n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    # both regtable should have the same regressors (and in the same order)\n",
    "\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    " #       Coefficients2 = regtable2.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "#        Coefficients2 = regtable2.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = ['#000000'] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.plot(position-0.1, regtable.loc['coefficient', Coefficient], marker='o', ms=8, color='blue',label = 'Like')\n",
    "        ax.plot(position+0.1, regtable2.loc['coefficient', Coefficient], marker='X', ms=8, color='red', label = 'Dislike')\n",
    "\n",
    "\n",
    "        ax.errorbar(position-0.1, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color='blue')\n",
    "        ax.errorbar(position+0.1, regtable2.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable2.loc['se', Coefficient]*1.96, lw=2, color='red')\n",
    "        \n",
    "        if position == 1:\n",
    "            ax.legend( prop={'size': 20})\n",
    "\n",
    " \n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Fixed Effects Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    sns.despine()\n",
    "    fig.savefig(str('SavedFigures/'+title +'.png'), dpi = 200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot_bar(regtable, mixtable, intercept=False, barcol='#000000', title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0 ):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "            \n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    if intercept == True:\n",
    "        XLim = (0, len(regtable.columns) + 1)\n",
    "        YLim = (round_to_5(np.min(mixtable)-0.2), round_to_5(np.max(mixtable)+0.2))\n",
    "    else:\n",
    "        XLim = (0, len(regtable.columns) )\n",
    "        YLim = (round_to_5(np.min(mixtable)-0.2), round_to_5(np.max(mixtable)+0.2))\n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = [barcol] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.bar(position, regtable.loc['coefficient', Coefficient], width=0.8,color=colourlist[position-1],)\n",
    "        ax.errorbar(position, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color='#000000')\n",
    "        \n",
    "   # Plot dots for the individual coefficients\n",
    "    coef_num = len(mixtable)\n",
    "    for i in range(1,coef_num):\n",
    "        part_coefs = mixtable[i]\n",
    "        position_parts= np.full(len(part_coefs), i, dtype=int)\n",
    "        jittr = np.random.uniform(low=-0.5,high=0.5,size=len(part_coefs))/2\n",
    "        ax.plot(position_parts+jittr, part_coefs, marker='o', ms=8, color='#000000',alpha=0.3,linestyle=\"None\")\n",
    "\n",
    "        \n",
    "\n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Regression Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot_bar2(regtable1, mixtable1,regtable2, mixtable2, intercept=False, barcol1='#000000',barcol2='#000000', title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0 ):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "            \n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # Set axis limits based on whether to include the intercept or not   \n",
    "    # Assumuing that regtable1 and regtable2 have exactly the same number of coefficients\n",
    "    if intercept == True:\n",
    "        XLim = (0, len(regtable1.columns) + 2)\n",
    "        YLim = (round_to_5(np.min([mixtable1,mixtable2]))-0.2, round_to_5(np.max([mixtable1,mixtable2]))+0.2)\n",
    "    else:\n",
    "        XLim = (0, len(regtable1.columns) +1)\n",
    "        YLim = (round_to_5(np.min([mixtable1,mixtable2]))-0.2, round_to_5(np.max([mixtable1,mixtable2]))+0.2)\n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    # Assumuing that regtable1 and regtable2 have exactly the same number of coefficients\n",
    "\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable1.columns\n",
    "    else:\n",
    "        if len(regtable1.columns)<len(mixtable1):\n",
    "            Coefficients = regtable1.columns\n",
    "        else:\n",
    "            Coefficients = regtable1.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    # Color for conditions 1 and 2\n",
    "    colourlist1 = [barcol1] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    colourlist2 = [barcol2] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        # Plot condition 1\n",
    "        ax.bar(position-0.2, regtable1.loc['coefficient', Coefficient], width=0.4,color=colourlist1[position-1],)\n",
    "        ax.errorbar(position-0.2, regtable1.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable1.loc['se', Coefficient]*1.96, lw=2, color='#000000')\n",
    "\n",
    "        # Plot condition 2\n",
    "        ax.bar(position+0.2, regtable2.loc['coefficient', Coefficient], width=0.4,color=colourlist2[position-1],)\n",
    "        ax.errorbar(position+0.2, regtable2.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable2.loc['se', Coefficient]*1.96, lw=2, color='#000000')\n",
    "\n",
    "        \n",
    "   # Plot dots for the individual coefficients\n",
    "    # Assumuing that mixtable1 and mixtable2 have exactly the same number of elements \n",
    "    \n",
    "    if intercept == True:\n",
    "        coef_num = range(0,len(mixtable1)) \n",
    "    else:\n",
    "        coef_num = range(1,len(mixtable1))\n",
    "        \n",
    "    for i in coef_num:\n",
    "        # Plot dots condition 1\n",
    "        part_coefs = mixtable1[i]\n",
    "        position_parts= np.full(len(part_coefs), i, dtype=int)\n",
    "        jittr = np.random.uniform(low=-0.2,high=0.2,size=len(part_coefs))/2\n",
    "        ax.plot(position_parts-0.2+jittr, part_coefs, marker='o', ms=8, color='#000000',alpha=0.3,linestyle=\"None\")\n",
    "\n",
    "        # Plot dots condition 1\n",
    "        part_coefs = mixtable2[i]\n",
    "        position_parts= np.full(len(part_coefs), i, dtype=int)\n",
    "        jittr = np.random.uniform(low=-0.2,high=0.2,size=len(part_coefs))/2\n",
    "        ax.plot(position_parts+0.2+jittr, part_coefs, marker='o', ms=8, color='#000000',alpha=0.3,linestyle=\"None\")\n",
    "        \n",
    "\n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable1.columns, rotation=0)        \n",
    "    else:\n",
    "        if len(regtable1.columns)<len(mixtable1):\n",
    "            ax.set_xticklabels(regtable1.columns, rotation=0)\n",
    "        else:    \n",
    "            ax.set_xticklabels(regtable1.columns[1:], rotation=0)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Regression Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regtable(fix, fix_se, names):\n",
    "    fixed_betas = DF(np.array(fix)); fixed_betas = fixed_betas.transpose(); fixed_betas.columns = names\n",
    "    fixed_betas.loc[1] = np.array(fix_se)\n",
    "    fixed_betas.loc[2] = fixed_betas.loc[0] - (fixed_betas.loc[1]*1.96)\n",
    "    fixed_betas.loc[3] = fixed_betas.loc[0] + (fixed_betas.loc[1]*1.96)\n",
    "    fixed_betas.index = ['coefficient', 'se', 'CImin', 'CImax']\n",
    "    return fixed_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl_plot2 (data_all,data_all2,x_variable,y_variable,color1 = '#000000',color2 = '#000000',x_varlabel = \"x_variable\" ,y_varlabel = \"y_variable\", data_label =('Correct', 'Error'), title = \"Pretty PLot\"):\n",
    "\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    sns.set(style='white', font_scale=1.8)\n",
    "    ax = sns.regplot(data=data_all, x= x_variable, y=y_variable, fit_reg=False, ci=0, color= color1, scatter_kws={'s':70,'alpha':0.3},)\n",
    "    ax = sns.regplot(data=data_all2, x= x_variable, y=y_variable, fit_reg=False, ci=0, color= color2, scatter_kws={'s':70,'alpha':0.3})\n",
    "    ax.set(ylabel=y_varlabel, xlabel=x_varlabel)\n",
    "\n",
    "    # For data 1\n",
    "    x=data_all[x_variable]\n",
    "    y=data_all[y_variable]\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    future = np.arange(min(x)-0.2, max(x)+0.2, 0.01)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    future_fit = np.polyval(fit_fn, future)\n",
    "    p1 = ax.plot(future, future_fit, color=color1, lw=3, label = data_label[0])\n",
    "    \n",
    "    results = pearsonr(data_all[x_variable], data_all[y_variable])\n",
    "    print (\"Pearson's r = {0}\".format(np.round(results[0], 3)), \"p = \", np.round(results[1], 3))\n",
    "    \n",
    "    # For data 2\n",
    "    x=data_all2[x_variable]\n",
    "    y=data_all2[y_variable]\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    future = np.arange(min(x)-0.2, max(x)+0.2, 0.01)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    future_fit = np.polyval(fit_fn, future)\n",
    "    p2 = ax.plot(future, future_fit, color=color2, lw=3,label = data_label[1] )\n",
    "    sns.despine()\n",
    "    #ax.set_title(title)    \n",
    "    results = pearsonr(data_all2[x_variable], data_all2[y_variable])\n",
    "    print (\"Pearson's r = {0}\".format(np.round(results[0], 3)), \"p = \", np.round(results[1], 3))\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "\n",
    "    #plt.legend((p1, p2), data_label )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_all_sbj_slope(moderator, modhigh, modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modhighcol='#000000', modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "#inputs example   \n",
    "#logisticplot_all('DDTSplit', 'High DDT', 'Low DDT', data=data_expL, xaxis='zDVal', yaxis='Choice', ylab='P(Right Item)', xlab='Difference in Value (DVal)',\n",
    "#                 modhighcol='#4F6A9A', modlowcol='#B5C8E9', title='empty', parvar='Part')\n",
    "\n",
    "\n",
    "    # Counter to know where to plot the particpant\n",
    "    order = 1\n",
    "    # Initialize the array to store coefs\n",
    "    coefs_all = []\n",
    "\n",
    "   # a list of all the participants in the dataset\n",
    "    participants = data.loc[:, 'Part'].unique()\n",
    "\n",
    "    # defining the figure size\n",
    "    sns.set_style('white')\n",
    "    fig = figure(figsize=(50,70))\n",
    "\n",
    "    for x in participants:\n",
    "        # defining the sub figures\n",
    "            sub={}\n",
    "            sub['%s' % x] = plt.subplot(int(len(participants)/5+1), 5, order)\n",
    "            \n",
    "            \n",
    "            # Extract dataframe for that particualt participant\n",
    "            data_in = data.loc[data['Part'] == x]\n",
    "           \n",
    "            sns.set(font_scale=1.5, style='white')\n",
    "           \n",
    "            # defining the sigmoid function\n",
    "            def model(x):\n",
    "                y = 1 / (1 + np.exp(-x))\n",
    "                return y\n",
    "\n",
    "            #sub = plt.subplot()\n",
    "            sub['%s' % x].set_title('participant %s' % x)\n",
    "\n",
    "\n",
    "            #run the classifier\n",
    "            clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "            # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "            logit_low = {}\n",
    "            logit_high = {}\n",
    "            logit_all = {}\n",
    "\n",
    "            \n",
    "            # I think this defines the problem space\n",
    "            X_test = np.linspace(-5,10,300)\n",
    "\n",
    "            # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "            # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "            clf.fit(data_in.loc[data_in[(data[moderator]==0)].index, xaxis][:, np.newaxis],\n",
    "                    data_in.loc[data_in[(data[moderator]==0)].index, yaxis])\n",
    "            logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "            #print ('Part: ',x , ' Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "            low_coef = clf.coef_\n",
    "            low_intercept = clf.intercept_\n",
    "            \n",
    "            # fitting the predictive logistic model for the high_confidence trials, for a participant specified by x\n",
    "            # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "            clf.fit(data_in.loc[data_in[(data_in[moderator]==1)].index, xaxis][:, np.newaxis],\n",
    "                    data_in.loc[data_in[(data_in[moderator]==1)].index, yaxis])\n",
    "            logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "            #print ('Part: ',x ,' High measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "            \n",
    "            high_coef = clf.coef_\n",
    "            high_intercept = clf.intercept_\n",
    "            \n",
    "            \n",
    "            # fitting the predictive logistic model for all the trials, for a participant specified by x\n",
    "            # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "            clf.fit(data_in[xaxis][:, np.newaxis],\n",
    "                    data_in[yaxis])\n",
    "            logit_all = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "            #print ('Part: ',x ,' High measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "            \n",
    "            all_coef = clf.coef_\n",
    "            all_intercept = clf.intercept_\n",
    "    \n",
    "            #Plotting the predictive lines\n",
    "            line_high = sub['%s' % x].plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "            line_low = sub['%s' % x].plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "            line_all = sub['%s' % x].plot(X_test, logit_all, color=\"#000000\", linewidth=3, label=modlow, zorder=5,linestyle='--')\n",
    "            \n",
    "            coefs_part= np.column_stack((x,low_coef,low_intercept,high_coef,high_intercept,all_coef,all_intercept))\n",
    "            coefs_all.append(coefs_part[0])\n",
    "\n",
    "            \n",
    "            #Plotting the binned data\n",
    "            data_in['DVBin2'] = data_in.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values[0]\n",
    "\n",
    "            # determine the x coordinates\n",
    "            x_cords= data.groupby('DVBin2')[xaxis].mean()\n",
    "\n",
    "            # determine low y coordinates\n",
    "            y_cords_low = data_in.loc[(data_in[moderator]==0), :].groupby('DVBin2')[yaxis].mean().values\n",
    "\n",
    "            # determine low y standard errors\n",
    "            test = pd.DataFrame(data_in.loc[(data_in[moderator]==0), :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "            y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "\n",
    "    \n",
    "            # determine high y coordinates\n",
    "            y_cords_high = data_in.loc[(data_in[moderator]==1), :].groupby('DVBin2')[yaxis].mean().values\n",
    "\n",
    "            # determine high y standard errors\n",
    "            test2 = pd.DataFrame(data_in.loc[data_in[moderator]==1, :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "            y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "\n",
    "            # plot the low points\n",
    "            plt.scatter(x_cords, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "            # plot low error bars\n",
    "            plt.errorbar(x_cords, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "\n",
    "            # plot the high points\n",
    "            plt.scatter(x_cords, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "            # plot high error bars\n",
    "            plt.errorbar(x_cords, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "\n",
    "    \n",
    "            # Set Labels\n",
    "           # sub['%s' % x].set_ylabel(ylab, fontsize=30)\n",
    "           # sub['%s' % x].set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "            # Set Ticks\n",
    "            sub['%s' % x].set_xticks((-5,-3,-1,1,3,5))\n",
    "            sub['%s' % x].set_yticks((0,0.25,0.5,0.75,1))\n",
    "            sub['%s' % x].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "            # Set Limits\n",
    "            sub['%s' % x].set_ylim(-0.01, 1.01)\n",
    "            sub['%s' % x].set_xlim(-5, 5)\n",
    "        \n",
    "\n",
    "            sns.despine()\n",
    "            \n",
    "            order += 1\n",
    "    \n",
    "    custom_lines = [Line2D([0], [0], color=modhighcol, lw=4),\n",
    "                Line2D([0], [0], color=modlowcol, lw=4)]\n",
    "    fig.legend(custom_lines, [modhigh, modlow],loc = 4)       \n",
    "\n",
    "    fig.text(0.5, 0.0, xlab, ha='center')\n",
    "    fig.text(0.0, 0.5, ylab, va='center', rotation='vertical')\n",
    "    \n",
    "    coefs_all = pd.DataFrame(coefs_all,columns=['Participant','Low Coef','Low Intercept','High Coef','High Intercept','All Coef','All Intercept'])\n",
    "    return coefs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score1(data_all, part_def,z_score_var):\n",
    "    z_matrix=[]\n",
    "    z_matrix_aux=[]\n",
    "\n",
    "    for i in (data_all[part_def].unique()):\n",
    "        Choicedata = data_all.loc[data_all[part_def] == i]    \n",
    "    \n",
    "        pX_A= pd.to_numeric(Choicedata[z_score_var]) \n",
    "        pX_zA= (pX_A - np.mean(pX_A))/np.std(pX_A)\n",
    "\n",
    "        z_matrix_aux= pX_zA.values\n",
    "    \n",
    "        for  j in range(len(z_matrix_aux)):    \n",
    "            z_matrix.append(z_matrix_aux[j])\n",
    "    return z_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl_plot(data_all,x_variable, x_varlabel,y_variable,y_varlabel):\n",
    "\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    sns.set(style='white', font_scale=1.8)\n",
    "    ax = sns.regplot(data=data_all, x= x_variable, y=y_variable, fit_reg=False, ci=0, color='#000000', scatter_kws={'s':70})\n",
    "    #sns.regplot(data=data_exp1, x='AbsDiffValue', y='Confidence', fit_reg=False, ci=0, color='Black', scatter_kws={'s':50})\n",
    "    ax.set(ylabel=y_varlabel, xlabel=x_varlabel)\n",
    "    #exp1 = mpatches.Patch(color='#000000', label='Experiment c1')\n",
    "    #exp2 = mpatches.Patch(color='#AAAAAA', label='Experiment 2')\n",
    "    #plt.legend(handles=[exp1, exp2], loc=3)\n",
    "    x=data_all[x_variable]\n",
    "    y=data_all[y_variable]\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    future = np.arange(min(x)-0.2, max(x)+0.2, 0.01)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    future_fit = np.polyval(fit_fn, future)\n",
    "    ax.plot(future, future_fit, color='Green', lw=3)\n",
    "    sns.despine()\n",
    "    #ax.set_title(title)    \n",
    "    results = pearsonr(data_all[x_variable], data_all[y_variable])\n",
    "    print (\"Pearson's r = {0}\".format(np.round(results[0], 3)), \"p = \", np.round(results[1], 3))\n",
    "    \n",
    "    plt.xlim(min(x),max(x))\n",
    "    plt.ylim(min(y),max(y))\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttestsPlot2(data1, data2,c1 ='#4F6A9A',c2 = '#AC5255',lab1 = \"Like\", lab2 = \"Dislike\",ylab = '',title = ''):\n",
    "\n",
    "    # t-TEST\n",
    "    diff = mean(data1) - mean(data2)\n",
    "    [s, p] = stats.ttest_rel(data1,data2)\n",
    "    print (\"MeanL = \"+ str(round(mean(data1),2))+ \"; MeanD = \"+ str(round(mean(data2),2))+\"; [Like - Dislike] =  \" + str(round(diff,2) ) +\"; t =  \" + str(round(s,2)) + \" ; p-value =\" + str(round(p,2)) )\n",
    "    \n",
    "        \n",
    "    # PLOT LIKE AND DISLIKE VARIABILITY\n",
    "        \n",
    "    # Set seaborn style for the plot\n",
    "    #fig = plt.figure(figsize=[6,10])\n",
    "    sns.set(style='white',font_scale=1.5)\n",
    "    jittr = np.random.uniform(low=-0.3,high=0.3,size=len(data1))    \n",
    "    plt.scatter([1]*len(data1)+jittr, data1, c= c1, alpha=0.7,label=lab1)\n",
    "    plt.scatter([2]*len(data2)+jittr, data2, c= c2, alpha=0.7,label=lab2)\n",
    "    \n",
    "    ## add lines between slope points in like and dislike for each participant\n",
    "    \n",
    "    for i in range(len(data1)):\n",
    "        plt.plot( [1 + jittr[i],2 + jittr[i]], [ data1[i] , data2[i]],'--', lw=1.0, color = 'black', alpha = 0.2)\n",
    "\n",
    "    se1 = std(data1)/sqrt(len(data1))\n",
    "    se2 = std(data2)/sqrt(len(data2))\n",
    "\n",
    "    plt.errorbar([1], [mean(data1)], yerr=se1*1.96, lw=2, color='#000000')\n",
    "    plt.errorbar([2], [mean(data2)], yerr=se2*1.96, lw=2, color='#000000')\n",
    "        \n",
    "    plt.scatter( [1] ,  [mean(data1)] , color = c1,s=140,edgecolors = 'black', )\n",
    "    plt.scatter( [2] ,  [mean(data2)] , color = c2,s=140,edgecolors = 'black', )\n",
    "\n",
    "    #legend(loc = 'best')\n",
    "    plt.xticks([1, 2,], [lab1, lab2],fontsize=25)\n",
    "    plt.ylabel(ylab, fontsize=25)\n",
    "    plt.title(title, fontsize=25)\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttestsBarPlot2(data1, data2,c1 ='#4F6A9A',c2 = '#AC5255',lab1 = \"Like\", lab2 = \"Dislike\",ylab = '',title = ''):\n",
    "\n",
    "    # t-TEST\n",
    "    diff = mean(data1) - mean(data2)\n",
    "    [s, p] = stats.ttest_rel(data1,data2)\n",
    "    print (\"MeanL = \"+ str(round(mean(data1),2))+ \"; MeanD = \"+ str(round(mean(data2),2))+\"; [Like - Dislike] =  \" + str(round(diff,2) ) +\"; t =  \" + str(round(s,2)) + \" ; p-value =\" + str(round(p,2)) )\n",
    "    \n",
    "    # Set seaborn style for the plot\n",
    "    fig = plt.figure(figsize=[6,10])\n",
    "    sns.set(style='white',font_scale=1.5)\n",
    "    jittr = np.random.uniform(low=-0.3,high=0.3,size=len(data1))    \n",
    "\n",
    "    se1 = std(data1)/sqrt(len(data1))\n",
    "    se2 = std(data2)/sqrt(len(data2))\n",
    "    \n",
    "    plt.bar( [1] ,  [mean(data1)] , color = c1, zorder = 0)\n",
    "    plt.bar( [2] ,  [mean(data2)] , color = c2, zorder = 0)\n",
    "    plt.errorbar([1], [mean(data1)], yerr=se1*1.96, lw=2, color='#000000')\n",
    "    plt.errorbar([2], [mean(data2)], yerr=se2*1.96, lw=2, color='#000000')\n",
    "                    \n",
    "    plt.scatter([1]*len(data1)+jittr, data1, c= '#000000', alpha=0.5,label=lab1)\n",
    "    plt.scatter([2]*len(data2)+jittr, data2, c= '#000000', alpha=0.5,label=lab2)\n",
    "    \n",
    "    ## add lines between slope points in like and dislike for each participant\n",
    "    \n",
    "    for i in range(len(data1)):\n",
    "        plt.plot( [1 + jittr[i],2 + jittr[i]], [ data1[i] , data2[i]],'--', lw=1.0, color = 'black', alpha = 0.2)\n",
    "\n",
    "    plt.xticks([1, 2,], [lab1, lab2],fontsize=25)\n",
    "    plt.ylabel(ylab, fontsize=25)\n",
    "    plt.title(title, fontsize=25)\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_like_dislike (data1,data2,modlow,modhigh, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',modlowcol='#AAAAAA',modhighcol='#000000', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the condition 1 \n",
    "    clf.fit(data1[xaxis][:, np.newaxis],\n",
    "            data1[yaxis][:, np.newaxis]) \n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    print ('Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "    # fitting the predictive logistic model for the condition 2 \n",
    "    clf.fit(data2[xaxis][:, np.newaxis],\n",
    "            data2[yaxis][:, np.newaxis ])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    \n",
    "    print ('high measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "\n",
    " \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20},frameon = False)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_like_dislike_bins (data1,data2,modlow,modhigh, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',modlowcol='#AAAAAA',modhighcol='#000000', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "\n",
    "    #Plotting the binned data\n",
    "    data1['DVBin2'] = data1.groupby(parvar).apply(parsplit, input=xaxis, quantiles=5).values\n",
    "    data2['DVBin2'] = data2.groupby(parvar).apply(parsplit, input=xaxis, quantiles=5).values\n",
    "    \n",
    "    # determine the x coordinates\n",
    "    x_cords1= data1.groupby('DVBin2')[xaxis].mean()\n",
    "    x_cords2= data2.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "    # determine low y coordinates\n",
    "    y_cords_low = data1.groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine low y standard errors\n",
    "    test = pd.DataFrame(data1.groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    \n",
    "    # determine high y coordinates\n",
    "    y_cords_high = data2.groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine high y standard errors\n",
    "    test2 = pd.DataFrame(data1.groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    # plot the low points\n",
    "    plt.scatter(x_cords1, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1,label=modlow)\n",
    "    # plot low error bars\n",
    "    plt.errorbar(x_cords1, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "    \n",
    "    # plot the high points\n",
    "    plt.scatter(x_cords2, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2,label=modhigh)\n",
    "    # plot high error bars\n",
    "    plt.errorbar(x_cords2, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "    \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "  #  sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "  #  sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "  #  sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "  #  sub.set_ylim(-0.01, 1.01)\n",
    "  #  sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=8, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_like_dislike_onlyOne (data1,modlow, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the condition 1 \n",
    "    clf.fit(data1[xaxis][:, np.newaxis],\n",
    "            data1[yaxis][:, np.newaxis]) \n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    print ('Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "\n",
    "    #Plotting the binned data\n",
    "    data1['DVBin2'] = data1.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values\n",
    "    \n",
    "    # determine the x coordinates\n",
    "    x_cords1= data1.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "    # determine low y coordinates\n",
    "    y_cords_low = data1.groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine low y standard errors\n",
    "    test = pd.DataFrame(data1.groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "\n",
    "    # plot the low points\n",
    "    plt.scatter(x_cords1, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "    # plot low error bars\n",
    "    plt.errorbar(x_cords1, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "        \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc='lower left', prop={'size':20},frameon = False,)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_like_dislike_plotAndbins (data1,data2,modlow,modhigh, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',modlowcol='#AAAAAA',modhighcol='#000000', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the condition 1 \n",
    "    clf.fit(data1[xaxis][:, np.newaxis],\n",
    "            data1[yaxis][:, np.newaxis]) \n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    print ('Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "    # fitting the predictive logistic model for the condition 2 \n",
    "    clf.fit(data2[xaxis][:, np.newaxis],\n",
    "            data2[yaxis][:, np.newaxis ])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    \n",
    "    print ('high measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "\n",
    "    #Plotting the binned data\n",
    "    data1['DVBin2'] = data1.groupby(parvar).apply(parsplit, input=xaxis, quantiles=5).values\n",
    "    data2['DVBin2'] = data2.groupby(parvar).apply(parsplit, input=xaxis, quantiles=5).values\n",
    "    \n",
    "    # determine the x coordinates\n",
    "    x_cords1= data1.groupby('DVBin2')[xaxis].mean()\n",
    "    x_cords2= data2.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "    # determine low y coordinates\n",
    "    y_cords_low = data1.groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine low y standard errors\n",
    "    test = pd.DataFrame(data1.groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    \n",
    "    # determine high y coordinates\n",
    "    y_cords_high = data2.groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine high y standard errors\n",
    "    test2 = pd.DataFrame(data1.groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    # plot the low points\n",
    "    plt.scatter(x_cords1, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "    # plot low error bars\n",
    "    plt.errorbar(x_cords1, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "    \n",
    "    # plot the high points\n",
    "    plt.scatter(x_cords2, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "    # plot high error bars\n",
    "    plt.errorbar(x_cords2, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "    \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc='lower left', prop={'size':20},frameon = False)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
