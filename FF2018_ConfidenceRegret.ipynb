{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##<script>\n",
    "##  jQuery(document).ready(function($) {  \n",
    "##  \n",
    "##  $(window).on('load', function(){\n",
    "##    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "##  });\n",
    "##  \n",
    "##  });\n",
    "##</script>\n",
    "##\n",
    "##<style type=\"text/css\">\n",
    "##  div#preloader { position: fixed; \n",
    "##      left: 0; \n",
    "##      top: 0; \n",
    "##      z-index: 999; \n",
    "##      width: 100%; \n",
    "##      height: 100%; \n",
    "##      overflow: visible; \n",
    "##      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center; \n",
    "##  }\n",
    "##\n",
    "##</style>\n",
    "##\n",
    "##<div id=\"preloader\">\n",
    "##\n",
    "##</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Variability Analysis\n",
    "### Dec 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "## 1. Load data and excluding participants\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants 6, 33, 7, 17, 25, 30 had to be excluded. Additionally, it was checked that trials in which participants did not fixate in any of the items were skipped. \n",
    "Therefore, 7 participants have been excluded.\n",
    "\n",
    "Total number subjects = 40\n",
    "Number of subjects remaining =33\n",
    "\n",
    "\n",
    "Extra Removal= particpants 2 and 35 are removeed due to problems in pair presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  4  5  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 26 27 28 29\n",
      " 31 32 34 36 37 38 39]\n",
      "Number of participants: 31\n"
     ]
    }
   ],
   "source": [
    "# Load data all participants\n",
    "#data_exp1 = pd.read_csv('/Users/pradyumna/Documents/gitDocs/FF2018/Output/DataFoodFramingNotebook_v1.csv') \n",
    "data_exp1 = pd.read_csv('/Users/pradyumna/Documents/GiTs/FF2018/Output/DataFoodFramingNotebook_v1.csv') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in [6, 7, 17, 25, 30, 33, 2 , 35]:\n",
    "    data_exp1 = data_exp1[(data_exp1.Part != i)]\n",
    "print (data_exp1[\"Part\"].unique())\n",
    "print ('Number of participants: ' + str(len(data_exp1[\"Part\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify the names\n",
    "data_exp1=data_exp1.rename(index=str, columns={\"ChosenITM\":\"Choice\", \n",
    "                              \"ChoiceRT\":\"RT\",\n",
    "                             \"RValue\":\"RVal\",\n",
    "                             \"LValue\":\"LVal\",\n",
    "                             \"zRValue\":\"zRVal\",\n",
    "                             \"zLValue\":\"zLVal\",                    \n",
    "                             \"tDDT\":\"DDT\",\n",
    "                             \"absDDT\":\"zAbsDDT\",\n",
    "                             \"lIA_DT\":\"LDwellTime\",\n",
    "                             \"rIA_DT\":\"RDwellTime\",\n",
    "                             \"tGSF\":\"GSF\",\n",
    "                             \"lastFixat\":\"LastFixat\",\n",
    "                             \"DV\":\"DVal\",\n",
    "                             \"zDV\":\"zDVal\",\n",
    "                             \"absDV\":\"AbsDVal\",\n",
    "                             \"zAbsDV\":\"zAbsDVal\",                    \n",
    "                             \"zChoiceRT\":\"zRT\",\n",
    "                             \"FamCh\":\"ChosenFam\",\n",
    "                              \"FamUnCh\":\"UnchosenFam\",\n",
    "                              \"ValCh\":\"ChosenVal\",\n",
    "                              \"ValUnCh\":\"UnchosenVal\",\n",
    "                             \"zFamCh\":\"zChosenFam\",\n",
    "                              \"zFamUnCh\":\"zUnchosenFam\",\n",
    "                              \"zValCh\":\"zChosenVal\",\n",
    "                              \"zValUnCh\":\"zUnchosenVal\",                   \n",
    "                              \"GSFMedSplit\":\"GSFSplit\",\n",
    "                            \"DDTMedSplit\":\"DDTSplit\"})\n",
    "data_exp1  = data_exp1.drop(['Unnamed: 0'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant lists and generate pair variability information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = data_exp1[\"Part\"].unique()\n",
    "pairsIds = data_exp1[\"PairID\"].unique()\n",
    "itemIds = data_exp1['LItem'].unique()\n",
    "itemIds.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate probabilities per participants\n",
    "\n",
    "Check for all the participants and each items the probability of being chosen considering all the instances when it appears in the experiment (separated by condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsID_prob_matrix = pd.DataFrame(columns=['Part','Item','Value','ItemProb'])\n",
    "\n",
    "\n",
    "for i in participants:\n",
    "    parID_variab = [0]*len(pairsIds) # Initialize vector with number of items per participant\n",
    "    # Use code 0 : not available (or equal value for both options) ; 1 : Consistent Correct; 2: Consistent Incorrect ; 3: Inconsistent Correct-Incorrect, 4 : Inconsistent Incorrect-Correct   \n",
    "    #for j in [1,2]:\n",
    "    datBlock = data_exp1.loc[ (data_exp1['Part'] == i)]\n",
    "    \n",
    "    pairID_info = []\n",
    "    pairsID_TotConfPair = []\n",
    "    itemsID_matrix = []\n",
    "\n",
    "    \n",
    "    \n",
    "    for k in range(0,len(itemIds)):\n",
    "        # Extract values for each item\n",
    "        datItemID= datBlock.loc[(datBlock['LItem'] == itemIds[k])]\n",
    "        item_value = datItemID['LVal'].values[0]\n",
    "        itemsID_matrix.append((i, itemIds[k], item_value))  # Participant, item, value\n",
    "    \n",
    "    itemsID_matrix = pd.DataFrame(itemsID_matrix,columns=['Part','Item','Value'])\n",
    "    itemsID_matrix = itemsID_matrix.sort_values('Value')\n",
    "    itemsID_matrix = itemsID_matrix.reset_index(drop =True)\n",
    "    \n",
    "    prob_item = np.zeros(len(itemsID_matrix))\n",
    "    acc_prob = 0\n",
    "    k = 0\n",
    "    jumpy = 1\n",
    "    # Calculate the accmulated\n",
    "    while k < len(itemsID_matrix):\n",
    "        \n",
    "        prob_item[k] = acc_prob\n",
    "        \n",
    "        if k+1 < len(itemsID_matrix):\n",
    "            if itemsID_matrix['Value'][k] == itemsID_matrix['Value'][k + 1]:\n",
    "                jumpy += 1\n",
    "                k +=1\n",
    "\n",
    "                continue\n",
    "        \n",
    "        acc_prob += 1/60*jumpy\n",
    "        jumpy = 1\n",
    "        k +=1\n",
    "\n",
    "    itemsID_matrix['ItemProb'] = prob_item \n",
    "    \n",
    "    itemsID_matrix = itemsID_matrix.sort_values('Item')\n",
    "    itemsID_matrix = itemsID_matrix.reset_index(drop =True)\n",
    "\n",
    "    itemsID_prob_matrix = pd.concat([itemsID_prob_matrix, itemsID_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to main dataframe probabilities info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbLItem = []\n",
    "ProbRItem = []\n",
    "ProbChosenItem = []\n",
    "ProbUnchosenItem = []\n",
    "\n",
    "for i in range(0,len(data_exp1)):\n",
    "    CurrPart = data_exp1.iloc[i].Part\n",
    "    ItemLeft = data_exp1.iloc[i].LItem\n",
    "    ItemRight = data_exp1.iloc[i].RItem\n",
    "    ChoiceT = data_exp1.iloc[i].Choice\n",
    "    \n",
    "    ProbLItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemLeft)].ItemProb.values[0])\n",
    "    ProbRItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemRight)].ItemProb.values[0])\n",
    "\n",
    "    \n",
    "    if ChoiceT == 0: # Chosen item is left\n",
    "        ProbChosenItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemLeft)].ItemProb.values[0])\n",
    "        ProbUnchosenItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemRight)].ItemProb.values[0])\n",
    "    else:\n",
    "        ProbChosenItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemLeft)].ItemProb.values[0])\n",
    "        ProbUnchosenItem.append(itemsID_prob_matrix.loc[(itemsID_prob_matrix['Part'] == CurrPart) & (itemsID_prob_matrix['Item'] == ItemRight)].ItemProb.values[0])\n",
    "\n",
    "        \n",
    "data_exp1['PCorrLItem'] = ProbLItem\n",
    "data_exp1['PCorrRItem'] = ProbRItem\n",
    "data_exp1['PWrongLItem'] = 1 - data_exp1['PCorrLItem'] \n",
    "data_exp1['PWrongRItem'] = 1 - data_exp1['PCorrRItem']\n",
    "        \n",
    "data_exp1['PCorrCh'] = ProbLItem\n",
    "data_exp1['PCorrUn'] = ProbRItem\n",
    "data_exp1['PWrongCh'] = 1 - data_exp1['PCorrCh'] \n",
    "data_exp1['PWrongUn'] = 1 - data_exp1['PCorrUn']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence influence by probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R  -i data_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Separating the data for both conditions \n",
    "data_exp1_Like <- data_exp1[ which(data_exp1$BlockCond=='1'), ]\n",
    "data_exp1_DisLike <- data_exp1[ which(data_exp1$BlockCond=='2'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"Confidence\"\n",
    "\n",
    "ModelConf0_L <- glm(Conf ~  ChosenVal + UnchosenVal + zRT + zTotVal + zGSF, data=data_exp1_Like)\n",
    "ModelConf0_D <- glm(Conf ~ ChosenVal + UnchosenVal + zRT + zTotVal + zGSF , data=data_exp1_DisLike)\n",
    "\n",
    "coefplot(ModelConf0_L,intercept=FALSE,vertical = FALSE,  col.pts='#4F6A9A', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-10, 10),main=title_plot)\n",
    "coefplot(ModelConf0_D,intercept=FALSE,vertical = FALSE,add=TRUE,  col.pts='#AC5255', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,main=title_plot)\n",
    "\n",
    "legend(\"topright\",  legend=c(\"Like\", \"Dislike\"),col=c('#4F6A9A', '#AC5255'), lty=1:1, cex=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"Confidence\"\n",
    "\n",
    "ModelConf1_L <- glm(Conf ~  LVal + RVal, data=data_exp1_Like)\n",
    "ModelConf1_D <- glm(Conf ~ LVal + RVal, data=data_exp1_DisLike)\n",
    "\n",
    "coefplot(ModelConf1_L,intercept=FALSE,vertical = FALSE,  col.pts='#4F6A9A', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-10, 10),main=title_plot)\n",
    "coefplot(ModelConf1_D,intercept=FALSE,vertical = FALSE,add=TRUE,  col.pts='#AC5255', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,main=title_plot)\n",
    "\n",
    "legend(\"topright\",  legend=c(\"Like\", \"Dislike\"),col=c('#4F6A9A', '#AC5255'), lty=1:1, cex=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it something like the total value effect? (There is a bias towards the left item, altough probably not significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"Confidence\"\n",
    "\n",
    "ModelConf2_L <- glm(Conf ~ ProbWrongChItem + ProbCorrUnItem, data=data_exp1_Like)\n",
    "ModelConf2_D <- glm(Conf ~ ProbWrongChItem + ProbCorrUnItem, data=data_exp1_DisLike)\n",
    "\n",
    "coefplot(ModelConf2_L,intercept=FALSE,vertical = FALSE,  col.pts='#4F6A9A', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-10, 10),main=title_plot)\n",
    "coefplot(ModelConf2_D,intercept=FALSE,vertical = FALSE,add=TRUE,  col.pts='#AC5255', cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,main=title_plot)\n",
    "\n",
    "legend(\"topright\",  legend=c(\"Like\", \"Dislike\"),col=c('#4F6A9A', '#AC5255'), lty=1:1, cex=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImpPkg'></a>\n",
    "Import Packages\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy', 'pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame as DF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "#np.random.seed(sum(map(ord, \"distributions\")))\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # packages for the logistic regression function to plot the logistic regression \n",
    "import scipy\n",
    "from scipy import stats, integrate\n",
    "from scipy.stats import mode\n",
    "from scipy.stats.stats import pearsonr # Pearson's correlation\n",
    "from copy import copy as copy\n",
    "import operator as operator\n",
    "import pylab\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Plotting tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%pylab inline\n",
    "figsize(5, 5)\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "# Added to avoid OMP:error#15\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "# Set up interface with R\n",
    "# Make it easy to set and find values in a multi-index DF\n",
    "idx = pd.IndexSlice\n",
    "# Set up interface with R\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RRuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "library(car)\n",
    "library(optimx)\n",
    "library(ggplot2)\n",
    "library(MASS)\n",
    "library(broom)\n",
    "library(dplyr)\n",
    "library(reshape2)\n",
    "library(arm)\n",
    "library(multcomp)\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LoadFunc'></a>\n",
    "# Defining Functions\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taken from Folke et al. (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_densities(data, var, xlim=(0,100), rug=True):\n",
    "    # a counter that tells us where a given participant's data should be plotted\n",
    "    order = 1\n",
    "\n",
    "    # a list of all the participants in the dataset\n",
    "    participants = data.loc[:, 'Part'].unique()\n",
    "\n",
    "    # defining the figure size\n",
    "    sns.set_style('white')\n",
    "    fig = figure(figsize=(15,70))\n",
    "\n",
    "    for x in participants:\n",
    "        # defining the sub figures\n",
    "            sub={}\n",
    "            sub['%s' % x] = plt.subplot(len(participants)/2, 3, order)\n",
    "            sns.kdeplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x], shade=True)\n",
    "            #if rug==True:\n",
    "            #    sns.rugplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x])\n",
    "            sub['%s' % x].set_title('participant %s' % x)\n",
    "            #sub['%s' % x].set_xlim(xlim)\n",
    "            order += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split variable into participantwise quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsplit(DF, input, quantiles):\n",
    "    qvalues = pd.qcut(DF[input], quantiles, labels = False)\n",
    "    return qvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full simple logistic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_all (moderator, modhigh, modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modhighcol='#000000', modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==0)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==0)].index, yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    print ('Low measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "\n",
    "    # fitting the predictive logistic model for the high_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==1)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==1)].index, yaxis])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    \n",
    "    print ('high measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5)\n",
    "\n",
    "\n",
    "    #Plotting the binned data\n",
    "    data['DVBin2'] = data.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values\n",
    "    \n",
    "    # determine the x coordinates\n",
    "    x_cords= data.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "    # determine low y coordinates\n",
    "    y_cords_low = data.loc[(data[moderator]==0), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine low y standard errors\n",
    "    test = pd.DataFrame(data.loc[(data[moderator]==0), :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    \n",
    "    # determine high y coordinates\n",
    "    y_cords_high = data.loc[(data[moderator]==1), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "    # determine high y standard errors\n",
    "    test2 = pd.DataFrame(data.loc[data[moderator]==1, :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "    y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    # plot the low points\n",
    "    plt.scatter(x_cords, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "    # plot low error bars\n",
    "    plt.errorbar(x_cords, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "    \n",
    "    # plot the high points\n",
    "    plt.scatter(x_cords, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "    # plot high error bars\n",
    "    plt.errorbar(x_cords, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "    \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full simple logistic graph (no bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_simpl (moderator, modhigh, modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modhighcol='#000000', modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    # Paula used these dictionaries to store the values of the predictive lines for all the participants.\n",
    "    logit_low = {}\n",
    "    logit_high = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==0)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==0)].index, yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('Low measure coef',clf.coef_)\n",
    "    \n",
    "    # fitting the predictive logistic model for the high_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data.loc[data[(data[moderator]==1)].index, xaxis][:, np.newaxis],\n",
    "            data.loc[data[(data[moderator]==1)].index, yaxis])\n",
    "    logit_high = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('High measure coef',clf.coef_)\n",
    "\n",
    "\n",
    "\n",
    "    #Plotting the predictive lines\n",
    "    line_high = sub.plot(X_test, logit_high, color=modhighcol, linewidth=5, label=modhigh, zorder=6)\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5) \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(loc=0, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Coefficients Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot(regtable, intercept=False, title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "\n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    if intercept == True:\n",
    "        XLim = (0.75, len(regtable.columns) + 0.25)\n",
    "        YLim = (round_to_5(regtable.loc['CImin', :].min()-0.1), round_to_5(regtable.loc['CImax', :].max()+0.2))\n",
    "    else:\n",
    "        XLim = (0.75, len(regtable.columns) - 0.75)\n",
    "        YLim = (round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()-0.2), round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()+0.2))\n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = ['#000000'] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.plot(position, regtable.loc['coefficient', Coefficient], marker='o', ms=8, color=colourlist[position-1],)\n",
    "        ax.errorbar(position, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color=colourlist[position-1])\n",
    "\n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Fixed Effects Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot2(regtable,regtable2, intercept=False, title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "\n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "\n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    \n",
    "       \n",
    "    \n",
    "    if intercept == True:\n",
    "        \n",
    "        XLim = (0.75, len(regtable.columns) + 0.25)\n",
    "        \n",
    "        #Determine the Ymax and Ymin for both regresions results\n",
    "        if round_to_5(regtable.loc['CImin', :].min()) < round_to_5(regtable2.loc['CImin', :].min()):\n",
    "            Ymin = round_to_5(regtable.loc['CImin', :].min()-0.5)\n",
    "        else :\n",
    "            Ymin = round_to_5(regtable2.loc['CImin',:].min()-0.5)\n",
    "        if round_to_5(regtable.loc['CImax', :].max()) > round_to_5(regtable2.loc['CImax', :].max()):\n",
    "            Ymax = round_to_5(regtable.loc['CImax', :].max()+0.5)\n",
    "        else :\n",
    "            Ymax = round_to_5(regtable2.loc['CImax', :].max()+0.5)      \n",
    "\n",
    "        YLim = (Ymin, Ymax)    \n",
    "    else:\n",
    "        XLim = (0.75, len(regtable.columns) - 0.75)\n",
    "        \n",
    "        #Determine the Ymax and Ymin for both regresions results\n",
    "        if round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()) < round_to_5(regtable2.loc['CImin', regtable.columns[1]:].min()):\n",
    "            Ymin = round_to_5(regtable.loc['CImin', regtable.columns[1]:].min()-0.5)\n",
    "        else :\n",
    "            Ymin = round_to_5(regtable2.loc['CImin',regtable.columns[1]:].min()-0.5)\n",
    "        if round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()) > round_to_5(regtable2.loc['CImax', regtable.columns[1]:].max()):\n",
    "            Ymax = round_to_5(regtable.loc['CImax', regtable.columns[1]:].max()+0.5)\n",
    "        else :\n",
    "            Ymax = round_to_5(regtable2.loc['CImax', regtable.columns[1]:].max()+0.5)      \n",
    "        \n",
    "        YLim = (Ymin, Ymax)\n",
    "    \n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    # both regtable should have the same regressors (and in the same order)\n",
    "\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    " #       Coefficients2 = regtable2.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "#        Coefficients2 = regtable2.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = ['#000000'] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.plot(position-0.1, regtable.loc['coefficient', Coefficient], marker='o', ms=8, color='blue',label = 'Like')\n",
    "        ax.plot(position+0.1, regtable2.loc['coefficient', Coefficient], marker='X', ms=8, color='red', label = 'Dislike')\n",
    "\n",
    "\n",
    "        ax.errorbar(position-0.1, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color='blue')\n",
    "        ax.errorbar(position+0.1, regtable2.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable2.loc['se', Coefficient]*1.96, lw=2, color='red')\n",
    "        \n",
    "        if position == 1:\n",
    "            ax.legend( prop={'size': 20})\n",
    "\n",
    " \n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Fixed Effects Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    sns.despine()\n",
    "    fig.savefig(str('SavedFigures/'+title +'.png'), dpi = 200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coefpresplot_bar(regtable, mixtable, intercept=False, barcol='#000000', title='Regression Coefficients', size='big', ylimits=(), ymultiple=0.5, ticklabsize=25, n_ET_predictors = 0 ):\n",
    "\n",
    "    # Import itertools so that we can iterate through the colours\n",
    "    import itertools\n",
    "    \n",
    "    # Import locators so that we can tidy up the yaxis\n",
    "    from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "    \n",
    "    # rounding function to get edges to even 0.5 values\n",
    "    def round_to(n, precision):\n",
    "        correction = 0.5 if n >= 0 else -0.5\n",
    "        return int( n/precision+correction ) * precision\n",
    "\n",
    "    def round_to_5(n):\n",
    "        return round_to(n, 0.5)\n",
    "            \n",
    "    # Set seaborn style for the plot\n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # Generate the figure\n",
    "    if size=='big':\n",
    "        fig = plt.figure(figsize=[20,8])\n",
    "    elif size=='long':\n",
    "        fig = plt.figure(figsize=[20,4])\n",
    "    elif size=='narrow':\n",
    "        fig = plt.figure(figsize=[10,4])\n",
    "        \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    gs = GridSpec(1,1,bottom=0.18,left=0.18,right=0.82)\n",
    "    ax = fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    # Set axis limits based on whether to include the intercept or not    \n",
    "    if intercept == True:\n",
    "        XLim = (0, len(regtable.columns) + 1)\n",
    "        YLim = (round_to_5(np.min(mixtable)-0.2), round_to_5(np.max(mixtable)+0.2))\n",
    "    else:\n",
    "        XLim = (0, len(regtable.columns) )\n",
    "        YLim = (round_to_5(np.min(mixtable)-0.2), round_to_5(np.max(mixtable)+0.2))\n",
    "    if ylimits != ():\n",
    "        YLim = ylimits\n",
    "    ax.set_xlim(XLim)\n",
    "    ax.set_ylim(YLim)\n",
    "    \n",
    "    # Draw a line through the 0-value on the y-axis\n",
    "    line = ax.plot(XLim, [0, 0], color='black', ls='--', alpha = 0.5, lw=3)\n",
    "    \n",
    "    \n",
    "    # If intercept is true, plot the coefficient for the intercept\n",
    "    if intercept == True:\n",
    "        Coefficients = regtable.columns\n",
    "    else:\n",
    "        Coefficients = regtable.columns[1:]\n",
    "        \n",
    "    # Determine the colours for the coefficients based on the n_ET_variable\n",
    "    n_predictors = len(Coefficients)\n",
    "    n_non_ET_predictors = n_predictors - n_ET_predictors\n",
    "    \n",
    "    colourlist = [barcol] * n_non_ET_predictors + ['#03719c'] * n_ET_predictors\n",
    "    \n",
    "        \n",
    "    # Plot all the coefficients with 95% CI\n",
    "    position = 0\n",
    "    for Coefficient in Coefficients:\n",
    "        position += 1\n",
    "        ax.bar(position, regtable.loc['coefficient', Coefficient], width=0.8,color=colourlist[position-1],)\n",
    "        ax.errorbar(position, regtable.loc['coefficient', Coefficient],\n",
    "                    yerr=regtable.loc['se', Coefficient]*1.96, lw=2, color='#000000')\n",
    "        \n",
    "   # Plot dots for the individual coefficients\n",
    "    coef_num = len(mixtable)\n",
    "    for i in range(1,coef_num):\n",
    "        part_coefs = mixtable[i]\n",
    "        position_parts= np.full(len(part_coefs), i, dtype=int)\n",
    "        jittr = np.random.uniform(low=-0.5,high=0.5,size=len(part_coefs))/2\n",
    "        ax.plot(position_parts+jittr, part_coefs, marker='o', ms=8, color='#000000',alpha=0.3,linestyle=\"None\")\n",
    "\n",
    "        \n",
    "\n",
    "    # Setting the x-axis major tick's location\n",
    "    ax.set_xticks(range(1, position+1))\n",
    "    \n",
    "    # set the y-axis major tick position\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(ymultiple))\n",
    "\n",
    "\n",
    "    # Setting the x-axis major tick's label\n",
    "    if intercept == True:\n",
    "        ax.set_xticklabels(regtable.columns, rotation=40)\n",
    "    else: \n",
    "        ax.set_xticklabels(regtable.columns[1:], rotation=40)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=ticklabsize)\n",
    "    ax.set_ylabel('Regression Coefficients', fontsize=18)\n",
    "    \n",
    "    # Autoformats the ticklabels for the xaxis\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regtable(fix, fix_se, names):\n",
    "    fixed_betas = DF(np.array(fix)); fixed_betas = fixed_betas.transpose(); fixed_betas.columns = names\n",
    "    fixed_betas.loc[1] = np.array(fix_se)\n",
    "    fixed_betas.loc[2] = fixed_betas.loc[0] - (fixed_betas.loc[1]*1.96)\n",
    "    fixed_betas.loc[3] = fixed_betas.loc[0] + (fixed_betas.loc[1]*1.96)\n",
    "    fixed_betas.index = ['coefficient', 'se', 'CImin', 'CImax']\n",
    "    return fixed_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_like_dislike(HV_part_like, LV_part_like, HV_part_dislike, LV_part_dislike, measure,ylimits=(0,100)):\n",
    "   # diff = mean(variability_part_like) - mean(variability_part_dislike)\n",
    "   # [s, p] = stats.ttest_rel(variability_part_like,variability_part_dislike)\n",
    "   # print (measure+ \"MeanL = \"+ str(mean(variability_part_like))+ \"; MeanD = \"+ str(mean(variability_part_dislike))+\"; [Like - Dislike] =  \" + str(diff) +\"; t =  \" + str(round(s,2)) + \" ; p-value =\" + str(p) )\n",
    "        \n",
    "    # PLOT LIKE AND DISLIKE VARIABILITY\n",
    "        \n",
    "    # Set seaborn style for the plot\n",
    "    fig = plt.figure(figsize=[6,10])\n",
    "    sns.set(style='white',font_scale=1.5)\n",
    "    jittr = np.random.uniform(low=-0.3,high=0.3,size=len(variability_part_like))    \n",
    "    p1 = plt.scatter([1]*len(HV_part_like)+jittr, HV_part_like, c='#4F6A9A', alpha=0.7,label=\"Like\")\n",
    "    p2 = plt.scatter([2]*len(LV_part_like)+jittr, LV_part_like, c='#4F6A9A', alpha=0.7,label=\"Like\")\n",
    "    p3 = plt.scatter([3]*len(HV_part_dislike)+jittr, HV_part_dislike, c='#AC5255', alpha=0.7,label=\"Dislike\")\n",
    "    p4 = plt.scatter([4]*len(LV_part_dislike)+jittr, LV_part_dislike, c='#AC5255', alpha=0.7,label=\"Dislike\")\n",
    "    \n",
    "    plt.ylim(ylimits)\n",
    "    \n",
    "    #legend(loc = 'best')\n",
    "    plt.xticks([1, 2,3,4], ['High', 'Low','High', 'Low'])\n",
    "    plt.ylabel(measure)\n",
    "    plt.xlabel('Variability')\n",
    "    plt.legend((p1, p3), ('Like', 'Dislike'))\n",
    "    sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter, delivered by Fastly, rendered by Rackspace.\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
